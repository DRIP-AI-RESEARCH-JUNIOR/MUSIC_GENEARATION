{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DCGanMusic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoFkvf8z+vmpDadu2VFAim",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRIP-AI-RESEARCH-JUNIOR/MUSIC_GENEARATION/blob/master/DCGanMusic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICLgoD5KzNW",
        "outputId": "fbab388a-1829-4738-c78b-76261142a2c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZElgUeWDG2A"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/midi /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_9-9VRv4Kyak"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Nottingham /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqGpFWzTCs_R"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "sys.path.append('midi')\n",
        "import torch.utils.data as data\n",
        "from midi_utils import midiread, midiwrite\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "from IPython.display import FileLink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TD_OcpkCzyW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBbkDflMDkAu"
      },
      "source": [
        "# DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNmPJmIkDZGn"
      },
      "source": [
        "def midi_filename_to_piano_roll(midi_filename):\n",
        "    \n",
        "    midi_data = midiread(midi_filename, dt=0.3)\n",
        "    \n",
        "    piano_roll = midi_data.piano_roll.transpose()\n",
        "    \n",
        "    # Pressed notes are replaced by 1\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    return piano_roll\n",
        " \n",
        " \n",
        "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
        "        \n",
        "    original_piano_roll_length = piano_roll.shape[1]\n",
        "    \n",
        "    padded_piano_roll = np.zeros((88, max_length))\n",
        "    padded_piano_roll[:] = pad_value\n",
        "    \n",
        "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
        " \n",
        "    return padded_piano_roll\n",
        " \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVdnxZM8Dm5c"
      },
      "source": [
        " class NotesGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
        "        \n",
        "        self.midi_folder_path = midi_folder_path\n",
        "        \n",
        "        midi_filenames = os.listdir(midi_folder_path)\n",
        "        \n",
        "        self.longest_sequence_length = longest_sequence_length\n",
        "        \n",
        "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
        "        \n",
        "        self.midi_full_filenames = list(midi_full_filenames)\n",
        "        \n",
        "        if longest_sequence_length is None:\n",
        "            \n",
        "            self.update_the_max_length()\n",
        "    \n",
        "    \n",
        "    def update_the_max_length(self):\n",
        "        \n",
        "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
        "        \n",
        "        max_length = max(sequences_lengths)\n",
        "        \n",
        "        self.longest_sequence_length = max_length\n",
        "                \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.midi_full_filenames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        midi_full_filename = self.midi_full_filenames[index]\n",
        "        \n",
        "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
        "\n",
        "        # padding sequence so that all of them have the same length\n",
        "        input_sequence_padded = pad_piano_roll(piano_roll, max_length=self.longest_sequence_length)\n",
        "        # print(input_sequence_padded.shape)\n",
        "                \n",
        "        input_sequence_padded = input_sequence_padded.transpose()\n",
        "        input_sequence_padded = torch.FloatTensor(input_sequence_padded).unsqueeze(0)\n",
        "\n",
        "        return input_sequence_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3vzu9-3Lkyb"
      },
      "source": [
        "trainset = NotesGenerationDataset('Nottingham/train/', longest_sequence_length=None)\n",
        " \n",
        "train_loader = data.DataLoader(trainset, batch_size=4,shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSAmK26ZMEUG",
        "outputId": "92486944-d372-4870-df97-1a31b38ba578"
      },
      "source": [
        "a = next(iter(train_loader))\n",
        "print(a.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 1491, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zepIK3M0OqhG"
      },
      "source": [
        "# UTILS FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBReFvnOtZQ"
      },
      "source": [
        "def conv_cond_concat(x, y):\n",
        "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
        "    x_shapes = x.shape\n",
        "    y_shapes = y.shape\n",
        "    y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])\n",
        "\n",
        "    return torch.cat((x, y2),1)\n",
        "\n",
        "def conv_prev_concat(x, y):\n",
        "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
        "    x_shapes = x.shape\n",
        "    y_shapes = y.shape\n",
        "    if x_shapes[2:] == y_shapes[2:]:\n",
        "        y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])\n",
        "\n",
        "        return torch.cat((x, y2),1)\n",
        "\n",
        "    else:\n",
        "        print(x_shapes[2:])\n",
        "        print(y_shapes[2:])\n",
        "\n",
        "\n",
        "\n",
        "def batch_norm_1d(x):\n",
        "    x_shape = x.shape[1]\n",
        "    batch_nor = nn.BatchNorm1d(x_shape, eps=1e-05, momentum=0.9, affine=True)\n",
        "    batch_nor = batch_nor.cuda()\n",
        "\n",
        "    output = batch_nor(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "def batch_norm_1d_cpu(x):\n",
        "    x_shape = x.shape[1]\n",
        "    # ipdb.set_trace()\n",
        "    # batch_nor = nn.BatchNorm1d(x_shape, eps=1e-05, momentum=0.9, affine=True)\n",
        "    # output = batch_nor(x)\n",
        "    output = x\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_norm_2d(x):\n",
        "    x_shape = x.shape[1]\n",
        "    batch_nor = nn.BatchNorm2d(x_shape, eps=1e-05, momentum=0.9, affine=True)\n",
        "    batch_nor = batch_nor.cuda()\n",
        "    output = batch_nor(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "def batch_norm_2d_cpu(x):\n",
        "    # x_shape = x.shape[1]\n",
        "    # batch_nor = nn.BatchNorm2d(x_shape, eps=1e-05, momentum=0.9, affine=True)\n",
        "    # batch_nor = batch_nor\n",
        "    # output = batch_nor(x)\n",
        "    output = x\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid_cross_entropy_with_logits(inputs,labels):\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "    output = loss(inputs, labels)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def reduce_mean(x):\n",
        "    output = torch.mean(x,0, keepdim = False)\n",
        "    output = torch.mean(output,-1, keepdim = False)\n",
        "    return output\n",
        "\n",
        "\n",
        "def reduce_mean_0(x):\n",
        "    output = torch.mean(x,0, keepdim = False)\n",
        "    return output\n",
        "\n",
        "\n",
        "def l2_loss(x,y):\n",
        "    loss_ = nn.MSELoss(reduction='sum')\n",
        "    l2_loss_ = loss_(x, y)/2\n",
        "    return l2_loss_\n",
        "\n",
        "\n",
        "\n",
        "def lrelu(x, leak=0.2):\n",
        "    z = torch.mul(x,leak)\n",
        "    return torch.max(x, z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohi7DEzsMiiQ"
      },
      "source": [
        "# DISCRIMINATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qte6MIOdY0ha"
      },
      "source": [
        "# Batch size during training\n",
        "batch_size = 4\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 16\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 16\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 5\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP0u97ylZAtp"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        nc = 1\n",
        "        ndf = 16\n",
        "        self.layer = nn.Sequential(\n",
        "            # input is 1 x 1491 x 88\n",
        "            nn.Conv2d(nc, ndf, (11,3), 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, (11,3), 3, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, (7,3), 3, 2, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, (9,3), 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, (7,5), 4, 1, bias=False),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.linear = nn.Conv2d(1, 1, (9,1),1,0,bias=False)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.layer(input)\n",
        "        x = self.linear(x)\n",
        "        out = self.sig(x)\n",
        "        return out,x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFkWWYzJZgbx",
        "outputId": "926c51d5-56fa-4f83-9089-f20f67fe9c64"
      },
      "source": [
        "inp = torch.randn(128,1,1491,88)\n",
        "d = Discriminator()\n",
        "out,x = d(inp)\n",
        "print(out.shape,x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 1, 1]) torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzDFS9IzNhHD"
      },
      "source": [
        "# GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saKEMUT6kmvc"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, 1, (9,1),1,0,bias=False),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(1, ngf * 8, (8,5), 4, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, (9,4), 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, (9,4), 3, 2, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, (12,4), 3, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc,  (11,4), 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x5PqNqKPBkN",
        "outputId": "2f7fdee9-4e60-4351-f843-58c9b71ec7fa"
      },
      "source": [
        "net_g = Generator()\n",
        "z = torch.randn(128,100,1,1)\n",
        "out = net_g(z)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 1491, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWCtT_9eO_G2"
      },
      "source": [
        "# testing model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N43YC8k1N2fl"
      },
      "source": [
        "# SANPLE GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4045uaRNxpN"
      },
      "source": [
        "class sample_generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(sample_generator, self).__init__()\n",
        "        self.gf_dim   = 64\n",
        "        self.y_dim   = 13\n",
        "        self.n_channel = 256\n",
        "\n",
        "        self.h1      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
        "        self.h2      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
        "        self.h3      = nn.ConvTranspose2d(in_channels=157, out_channels=pitch_range, kernel_size=(2,1), stride=(2,2))\n",
        "        self.h4      = nn.ConvTranspose2d(in_channels=157, out_channels=1, kernel_size=(1,pitch_range), stride=(1,2))\n",
        "\n",
        "        self.h0_prev = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1,pitch_range), stride=(1,2))\n",
        "        self.h1_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
        "        self.h2_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
        "        self.h3_prev = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,1), stride=(2,2))\n",
        "\n",
        "        self.linear1 = nn.Linear(113,1024)\n",
        "        self.linear2 = nn.Linear(1037,self.gf_dim*2*2*1)\n",
        "\n",
        "    def forward(self, z, prev_x, y ,batch_size,pitch_range):\n",
        "\n",
        "        # h3_prev = F.leaky_relu(self.batch_nor_256(self.h0_prev(prev_x)),0.2)\n",
        "        h0_prev = lrelu(batch_norm_2d_cpu(self.h0_prev(prev_x)),0.2)   #[72, 16, 16, 1]\n",
        "        h1_prev = lrelu(batch_norm_2d_cpu(self.h1_prev(h0_prev)),0.2)  #[72, 16, 8, 1]\n",
        "        h2_prev = lrelu(batch_norm_2d_cpu(self.h2_prev(h1_prev)),0.2)  #[72, 16, 4, 1]\n",
        "        h3_prev = lrelu(batch_norm_2d_cpu(self.h3_prev(h2_prev)),0.2)  #[72, 16, 2, 1])\n",
        "\n",
        "        yb = y.view(batch_size,  self.y_dim, 1, 1)  #(72,13,1,1)\n",
        "\n",
        "        z = torch.cat((z,y),1)         #(72,113)\n",
        "\n",
        "        h0 = F.relu(batch_norm_1d_cpu(self.linear1(z)))    #(72,1024)\n",
        "        h0 = torch.cat((h0,y),1)   #(72,1037)\n",
        "\n",
        "        h1 = F.relu(batch_norm_1d_cpu(self.linear2(h0)))   #(72, 256)\n",
        "        h1 = h1.view(batch_size, self.gf_dim * 2, 2, 1)     #(72,128,2,1)\n",
        "        h1 = conv_cond_concat(h1,yb) #(b,141,2,1)\n",
        "        h1 = conv_prev_concat(h1,h3_prev)  #(72, 157, 2, 1)\n",
        "\n",
        "        h2 = F.relu(batch_norm_2d_cpu(self.h1(h1)))  #(72, 128, 4, 1)\n",
        "        h2 = conv_cond_concat(h2,yb) #([72, 141, 4, 1])\n",
        "        h2 = conv_prev_concat(h2,h2_prev)  #([72, 157, 4, 1])\n",
        "\n",
        "        h3 = F.relu(batch_norm_2d_cpu(self.h2(h2)))  #([72, 128, 8, 1]) \n",
        "        h3 = conv_cond_concat(h3,yb)  #([72, 141, 8, 1])\n",
        "        h3 = conv_prev_concat(h3,h1_prev) #([72, 157, 8, 1])\n",
        "\n",
        "        h4 = F.relu(batch_norm_2d_cpu(self.h3(h3)))  #([72, 128, 16, 1])\n",
        "        h4 = conv_cond_concat(h4,yb)  #([72, 141, 16, 1])\n",
        "        h4 = conv_prev_concat(h4,h0_prev) #([72, 157, 16, 1])\n",
        "\n",
        "        g_x = torch.sigmoid(self.h4(h4)) #([72, 1, 16, 128])\n",
        "\n",
        "        return g_x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AToAjuZWON-m"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t00bhgEPOQuk"
      },
      "source": [
        "def train(netG, netD, optimizerG, optimizerD,criterion ,epochs,dataloader, batch_size, nz, device=torch.device('cuda')):\n",
        "  \n",
        "  fixed_noise = torch.randn(batch_size, nz, device=device)\n",
        "  netD.train()\n",
        "  netG.train()\n",
        "  \n",
        "  real_label = 1\n",
        "  fake_label = 0\n",
        "  average_lossD = 0\n",
        "  average_lossG = 0\n",
        "  average_D_x   = 0\n",
        "  average_D_G_z = 0\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    sum_lossD = 0\n",
        "    sum_lossG = 0\n",
        "    sum_D_x   = 0\n",
        "    sum_D_G_z = 0\n",
        "    average_lossD = 0\n",
        "    average_lossG = 0\n",
        "    average_D_x   = 0\n",
        "    average_D_G_z = 0\n",
        "    \n",
        "    for i, (data) in enumerate(train_loader, 0):\n",
        "      \n",
        "      #############################################################\n",
        "      # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "      #############################################################\n",
        "      \n",
        "      # train with real      \n",
        "      netD.zero_grad()\n",
        "      real_cpu = data.to(device)\n",
        "      \n",
        "      batch_size = real_cpu.size()[0]\n",
        "      label = torch.full((batch_size,), real_label,dtype=torch.float, device=device)\n",
        "      D, D_logits = netD(real_cpu)\n",
        "      \n",
        "      #####loss\n",
        "      d_loss_real = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits, 0.9*torch.ones_like(D)))\n",
        "      d_loss_real.backward(retain_graph=True)\n",
        "      D_x = D.mean().item()\n",
        "      sum_D_x += D_x \n",
        "      \n",
        "      # train with fake\n",
        "      noise = torch.randn(batch_size, nz,1,1, device=device)\n",
        "      fake = netG(noise)\n",
        "      label.fill_(fake_label)\n",
        "      D_, D_logits_ = netD(fake.detach())\n",
        "      d_loss_fake = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits_, torch.zeros_like(D_)))\n",
        "      \n",
        "      d_loss_fake.backward(retain_graph=True)\n",
        "      D_G_z1 = D_.mean().item()\n",
        "      errD = d_loss_real + d_loss_fake\n",
        "      errD = errD.item()\n",
        "      sum_lossD += errD\n",
        "      optimizerD.step()\n",
        "      \n",
        "      #############################################\n",
        "      # (2) Update G network: maximize log(D(G(z)))\n",
        "      #############################################\n",
        "      \n",
        "      netG.zero_grad()\n",
        "      label.fill_(real_label)  # fake labels are real for generator cost\n",
        "      D_, D_logits_= netD(fake)\n",
        "      \n",
        "      ###loss\n",
        "      errG = reduce_mean(sigmoid_cross_entropy_with_logits(D_logits_, torch.ones_like(D_)))\n",
        "\n",
        "      errG.backward()\n",
        "      sum_lossG +=errG\n",
        "      D_G_z2 = D_.mean().item()\n",
        "      sum_D_G_z += D_G_z2\n",
        "      optimizerG.step()\n",
        "  \n",
        "    average_lossD = (sum_lossD / len(train_loader))\n",
        "    average_lossG = (sum_lossG / len(train_loader))\n",
        "    average_D_x = (sum_D_x / len(train_loader))\n",
        "    average_D_G_z = (sum_D_G_z / len(train_loader))\n",
        "  \n",
        "    # lossD_list.append(average_lossD)\n",
        "    # lossG_list.append(average_lossG)\n",
        "    # D_x_list.append(average_D_x)\n",
        "    # D_G_z_list.append(average_D_G_z)\n",
        "  \n",
        "    print('==> Epoch: {} Average lossD: {:.10f} average_lossG: {:.10f},average D(x): {:.10f},average D(G(z)): {:.10f} '.format(\n",
        "     epoch, average_lossD,average_lossG,average_D_x, average_D_G_z))\n",
        "    del average_lossD,average_lossG,data,average_D_x,real_cpu,average_D_G_z,sum_lossD,sum_lossG,sum_D_x,sum_D_G_z,label,noise,fake,D,D_,D_logits,D_logits_,d_loss_fake,d_loss_real\n",
        "    torch.cuda.empty_cache()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qohk10gP72rY"
      },
      "source": [
        "def train(netG, netD, optimizerG, optimizerD,criterion ,epochs,dataloader, batch_size, nz, device=torch.device('cuda')):\n",
        "    img_list = []\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "    real_label = 1.\n",
        "    fake_label = 0.\n",
        "\n",
        "    print(\"Starting Training Loop...\")\n",
        "    # For each epoch\n",
        "    for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "            netD.zero_grad()\n",
        "        # Format batch\n",
        "            real_cpu = data.to(device)\n",
        "            b_size = real_cpu.size()[0]\n",
        "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        # Forward pass real batch through D\n",
        "            output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "            errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "            output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "            errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "            errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "            output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "            errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "            optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "            if i % 50 == 0:\n",
        "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                      % (epoch, num_epochs, i, len(dataloader),\n",
        "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "            # G_losses.append(errG.item())\n",
        "            # D_losses.append(errD.item())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcNNHY6ZOTqZ"
      },
      "source": [
        "def main():\n",
        "  epochs = 50\n",
        "  lr = 0.0002\n",
        "  \n",
        "  device = torch.device('cuda')\n",
        "  \n",
        "  netG = Generator().to(device)\n",
        "  netD = Discriminator().to(device)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  \n",
        "  optimizerD = optim.Adam(netD.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "  optimizerG = optim.Adam(netG.parameters(), lr=0.01, betas=(0.5, 0.999)) \n",
        "  train(netG, netD, optimizerG, optimizerD,criterion ,epochs,train_loader,batch_size, nz, device=device)\n",
        "  return netG,netD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xu0uUce04ojG"
      },
      "source": [
        "netg,netd = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vJT8zmCxVSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e03a43-df2b-4193-eb00-550fd2b808e4"
      },
      "source": [
        "noise = torch.randn(1, 100, 1, 1, device=device)\n",
        "sample = netg(noise)\n",
        "sample = sample.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
        "print(sample)\n",
        "midiwrite('trans'+'_'+'.mid', sample, dt=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.83399734e-05 1.18721153e-04 1.29139312e-06 ... 1.50917201e-09\n",
            "  1.22829225e-09 5.81557769e-03]\n",
            " [1.07799087e-05 3.82893689e-10 1.96181707e-13 ... 5.96187263e-16\n",
            "  6.27563707e-20 7.65621280e-06]\n",
            " [7.14079878e-14 1.27391608e-08 4.10589536e-08 ... 2.14755921e-11\n",
            "  2.08678574e-10 3.19685932e-06]\n",
            " ...\n",
            " [7.71827810e-03 4.39537944e-05 3.51350438e-09 ... 6.90341622e-05\n",
            "  1.31781865e-08 1.66054461e-02]\n",
            " [1.93011072e-02 4.77180174e-06 2.85269980e-05 ... 3.68390116e-04\n",
            "  8.72158864e-07 3.50485481e-02]\n",
            " [1.91087216e-01 5.69139328e-03 7.05877261e-04 ... 9.95415170e-03\n",
            "  2.51100701e-05 1.39855981e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2nhGHTc4bz2",
        "outputId": "b5c9566d-5737-4f5b-d612-36e3473d4278"
      },
      "source": [
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fluid-soundfont-gm libfluidsynth1 libqt5x11extras5 qsynth\n",
            "Suggested packages:\n",
            "  fluid-soundfont-gs timidity jackd\n",
            "The following NEW packages will be installed:\n",
            "  fluid-soundfont-gm fluidsynth libfluidsynth1 libqt5x11extras5 qsynth\n",
            "0 upgraded, 5 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 150 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluid-soundfont-gm all 3.1-5.1 [119 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth1 amd64 1.1.9-1 [137 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluidsynth amd64 1.1.9-1 [20.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libqt5x11extras5 amd64 5.9.5-0ubuntu1 [8,596 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 qsynth amd64 0.5.0-2 [191 kB]\n",
            "Fetched 120 MB in 7s (16.8 MB/s)\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Selecting previously unselected package fluidsynth.\n",
            "Preparing to unpack .../fluidsynth_1.1.9-1_amd64.deb ...\n",
            "Unpacking fluidsynth (1.1.9-1) ...\n",
            "Selecting previously unselected package libqt5x11extras5:amd64.\n",
            "Preparing to unpack .../libqt5x11extras5_5.9.5-0ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
            "Selecting previously unselected package qsynth.\n",
            "Preparing to unpack .../qsynth_0.5.0-2_amd64.deb ...\n",
            "Unpacking qsynth (0.5.0-2) ...\n",
            "Setting up libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluidsynth (1.1.9-1) ...\n",
            "Setting up qsynth (0.5.0-2) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zImCgTvO4jlR",
        "outputId": "93751b09-f98f-4b22-e6c0-9b0855cb077a"
      },
      "source": [
        "!fluidsynth -ni font.sf2 trans_.mid -F trans_.wav -r 44100\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FluidSynth version 1.1.9\n",
            "Copyright (C) 2000-2018 Peter Hanappe and others.\n",
            "Distributed under the LGPL license.\n",
            "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
            "\n",
            "Rendering audio to file 'trans_.wav'..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1QPPv7840gH"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio('trans_.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6Y-9ZPC1m7"
      },
      "source": [
        "# test"
      ]
    }
  ]
}