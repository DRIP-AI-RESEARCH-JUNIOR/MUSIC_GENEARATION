{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Rnn_music.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oS4_Vzih73xp",
        "HItE4rcfepc_",
        "OLcK94Faz198"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6WP9Avo3b2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c604b6-00ed-4728-839f-63d16685c2c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQMcBZEP6Y8D"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Nottingham /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39C4e6DD6ftk"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/midi /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9pFhTJZ186V"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "sys.path.append('midi')\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0kur4RU3ZdI"
      },
      "source": [
        "from midi_utils import midiread, midiwrite\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "from IPython.display import FileLink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmds6E143mOl"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35lkdEI13eBW"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        " \n",
        " \n",
        "def midi_filename_to_piano_roll(midi_filename):\n",
        "    \n",
        "    midi_data = midiread(midi_filename, dt=0.3)\n",
        "    \n",
        "    piano_roll = midi_data.piano_roll.transpose()\n",
        "    \n",
        "    # Pressed notes are replaced by 1\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    return piano_roll\n",
        " \n",
        " \n",
        "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
        "        \n",
        "    original_piano_roll_length = piano_roll.shape[1]\n",
        "    \n",
        "    padded_piano_roll = np.zeros((88, max_length))\n",
        "    padded_piano_roll[:] = pad_value\n",
        "    \n",
        "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
        " \n",
        "    return padded_piano_roll\n",
        " \n",
        " \n",
        "class NotesGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
        "        \n",
        "        self.midi_folder_path = midi_folder_path\n",
        "        \n",
        "        midi_filenames = os.listdir(midi_folder_path)\n",
        "        \n",
        "        self.longest_sequence_length = longest_sequence_length\n",
        "        \n",
        "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
        "        \n",
        "        self.midi_full_filenames = list(midi_full_filenames)\n",
        "        \n",
        "        if longest_sequence_length is None:\n",
        "            \n",
        "            self.update_the_max_length()\n",
        "    \n",
        "    \n",
        "    def update_the_max_length(self):\n",
        "        \n",
        "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
        "        \n",
        "        max_length = max(sequences_lengths)\n",
        "        \n",
        "        self.longest_sequence_length = max_length\n",
        "                \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.midi_full_filenames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        midi_full_filename = self.midi_full_filenames[index]\n",
        "        \n",
        "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
        "        # print(\"piano_roll\",piano_roll.shape)\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        sequence_length = piano_roll.shape[1] - 1\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        input_sequence = piano_roll[:, :-1]\n",
        "        # print(\"input_sequence\",input_sequence.shape)\n",
        "        ground_truth_sequence = piano_roll[:, 1:]\n",
        "        # print(\"ground_truth\",ground_truth_sequence.shape)\n",
        "                \n",
        "        # padding sequence so that all of them have the same length\n",
        "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
        "        # print(\"input_sequence_padded\",input_sequence_padded.shape)\n",
        "        \n",
        "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
        "        # print(\"ground_sequence_padded\",ground_truth_sequence_padded.shape)\n",
        "                \n",
        "        input_sequence_padded = input_sequence_padded.transpose()\n",
        "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
        "        \n",
        "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
        " \n",
        "    \n",
        "def post_process_sequence_batch(batch_tuple):\n",
        "    \n",
        "    input_sequences, output_sequences, lengths = batch_tuple\n",
        "    \n",
        "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "    splitted_lengths_batch = lengths.split(split_size=1)\n",
        " \n",
        "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                               splitted_output_sequence_batch,\n",
        "                               splitted_lengths_batch)\n",
        " \n",
        "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                         key=lambda p: int(p[2]),\n",
        "                                         reverse=True)\n",
        " \n",
        "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        " \n",
        "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "    \n",
        "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    \n",
        "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "    \n",
        "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
        "    \n",
        "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElwXNHES4EBW"
      },
      "source": [
        "trainset = NotesGenerationDataset('Nottingham/train/', longest_sequence_length=None)\n",
        " \n",
        "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqzQzpeT6487"
      },
      "source": [
        "valset = NotesGenerationDataset('Nottingham/valid/', longest_sequence_length=None)\n",
        " \n",
        "valset_loader = data.DataLoader(valset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWAHm_T5ABF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c186e7-8630-4d5f-9cc7-6a036015637f"
      },
      "source": [
        "a = next(iter(trainset_loader))\n",
        "print(a[0].shape, a[1].shape, a[2].shape)\n",
        "a[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1491, 88]) torch.Size([8, 1491, 88]) torch.Size([8, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[214],\n",
              "        [604],\n",
              "        [214],\n",
              "        [214],\n",
              "        [213],\n",
              "        [266],\n",
              "        [214],\n",
              "        [214]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urjG40vc5z0b"
      },
      "source": [
        "## RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWYCVuyh56CP"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
        "        \n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        \n",
        "        self.bn = nn.BatchNorm1d(hidden_size)\n",
        "        \n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "        \n",
        "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    \n",
        "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
        "        batch_size = input_sequences.shape[1]\n",
        "        # print(\"input_sequences\",input_sequences.shape)\n",
        "        notes_encoded = self.notes_encoder(input_sequences)\n",
        "        \n",
        "        notes_encoded_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
        "        notes_encoded_norm = self.bn(notes_encoded_rolled)\n",
        "        \n",
        "        notes_encoded_norm_drop = nn.Dropout(0.25)(notes_encoded_norm)\n",
        "        notes_encoded_complete = notes_encoded_norm_drop.permute(2,0,1)\n",
        "        \n",
        "        # Here we run rnns only on non-padded regions of the batch\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded_complete, input_sequences_lengths)\n",
        "        outputs, hidden = self.lstm(packed, hidden)\n",
        "        \n",
        "        # Here we unpack sequence(back to padded)\n",
        "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        \n",
        "        outputs_norm = self.bn(outputs.permute(1,2,0).contiguous())\n",
        "        outputs_drop = nn.Dropout(0.1)(outputs_norm)\n",
        "        # print(\"outputs_drop\",outputs_drop.shape)\n",
        "        logits = self.logits_fc(outputs_drop.permute(2,0,1))\n",
        "        # print(\"logits_per\",logits.shape)\n",
        "        logits = logits.transpose(0, 1).contiguous()\n",
        "        # print(\"logits_trans\",logits.shape)\n",
        "        \n",
        "        neg_logits = (1 - logits)\n",
        "        # print(\"neg_logits\",neg_logits.shape)\n",
        "        # Since the BCE loss doesn't support masking,crossentropy is used\n",
        "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
        "        # print(\"binary_logits\",binary_logits.shape)\n",
        "        logits_flatten = binary_logits.view(-1, 2)\n",
        "        # print(\"logits_flatten\",logits_flatten.shape)\n",
        "        return logits_flatten, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KAP3tXq6JrG"
      },
      "source": [
        "model = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_val = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR5E8raA6Uhc"
      },
      "source": [
        "def validate(model):\n",
        "    model.eval()\n",
        "    full_val_loss = 0.0\n",
        "    overall_sequence_length = 0.0\n",
        " \n",
        "    for batch in valset_loader:\n",
        " \n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        " \n",
        "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
        " \n",
        "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
        " \n",
        "        logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
        "        # print(\"logits\",logits.shape)\n",
        " \n",
        "        loss = criterion_val(logits, output_sequences_batch_var)\n",
        " \n",
        "        full_val_loss += loss.item()\n",
        "        overall_sequence_length += sum(sequences_lengths)\n",
        " \n",
        "    return full_val_loss / (overall_sequence_length * 88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtsfh1Fr7Gl8"
      },
      "source": [
        "clip = 1.0\n",
        "epochs_number = 10\n",
        "sample_history = []\n",
        "best_val_loss = float(\"inf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuHDnsS27NlL"
      },
      "source": [
        "def lrfinder(start, end, model, trainset_loader, epochs=2):\n",
        "    model.train() # into training mode\n",
        "    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
        "    optimizer = torch.optim.Adam(rnn.parameters(),start)\n",
        "    loss_list = []\n",
        "    ctr = 0\n",
        "    \n",
        "    for epoch_number in range(epochs):\n",
        "        epoch_loss = []\n",
        "        for batch in trainset_loader:\n",
        "            optimizer.param_groups[0]['lr'] = lrs[ctr]\n",
        "            ctr = ctr+1\n",
        " \n",
        "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        " \n",
        "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
        " \n",
        "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
        " \n",
        "            optimizer.zero_grad()\n",
        " \n",
        "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
        " \n",
        "            loss = criterion(logits, output_sequences_batch_var)\n",
        "            loss_list.append(loss.item())\n",
        "            loss.backward()\n",
        " \n",
        "            torch.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
        " \n",
        "            optimizer.step()\n",
        "        print('Epoch %d' % epoch_number)\n",
        "    plt.plot(lrs, loss_list)\n",
        "    return lrs, loss_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9gl3Sn7OdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ca63c15-db36-4e77-e338-8b2c4d2a3d29"
      },
      "source": [
        "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
        "rnn = rnn.cuda()\n",
        "lrs, losses = lrfinder(1e-4, 1e-1*5, rnn, trainset_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_sequences torch.Size([429, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 429])\n",
            "logits_per torch.Size([429, 8, 88])\n",
            "logits_trans torch.Size([8, 429, 88])\n",
            "neg_logits torch.Size([8, 429, 88])\n",
            "binary_logits torch.Size([8, 429, 88, 2])\n",
            "logits_flatten torch.Size([302016, 2])\n",
            "input_sequences torch.Size([374, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 374])\n",
            "logits_per torch.Size([374, 8, 88])\n",
            "logits_trans torch.Size([8, 374, 88])\n",
            "neg_logits torch.Size([8, 374, 88])\n",
            "binary_logits torch.Size([8, 374, 88, 2])\n",
            "logits_flatten torch.Size([263296, 2])\n",
            "input_sequences torch.Size([428, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 428])\n",
            "logits_per torch.Size([428, 8, 88])\n",
            "logits_trans torch.Size([8, 428, 88])\n",
            "neg_logits torch.Size([8, 428, 88])\n",
            "binary_logits torch.Size([8, 428, 88, 2])\n",
            "logits_flatten torch.Size([301312, 2])\n",
            "input_sequences torch.Size([214, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 214])\n",
            "logits_per torch.Size([214, 8, 88])\n",
            "logits_trans torch.Size([8, 214, 88])\n",
            "neg_logits torch.Size([8, 214, 88])\n",
            "binary_logits torch.Size([8, 214, 88, 2])\n",
            "logits_flatten torch.Size([150656, 2])\n",
            "input_sequences torch.Size([216, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 216])\n",
            "logits_per torch.Size([216, 8, 88])\n",
            "logits_trans torch.Size([8, 216, 88])\n",
            "neg_logits torch.Size([8, 216, 88])\n",
            "binary_logits torch.Size([8, 216, 88, 2])\n",
            "logits_flatten torch.Size([152064, 2])\n",
            "input_sequences torch.Size([321, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 321])\n",
            "logits_per torch.Size([321, 8, 88])\n",
            "logits_trans torch.Size([8, 321, 88])\n",
            "neg_logits torch.Size([8, 321, 88])\n",
            "binary_logits torch.Size([8, 321, 88, 2])\n",
            "logits_flatten torch.Size([225984, 2])\n",
            "input_sequences torch.Size([214, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 214])\n",
            "logits_per torch.Size([214, 8, 88])\n",
            "logits_trans torch.Size([8, 214, 88])\n",
            "neg_logits torch.Size([8, 214, 88])\n",
            "binary_logits torch.Size([8, 214, 88, 2])\n",
            "logits_flatten torch.Size([150656, 2])\n",
            "input_sequences torch.Size([268, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 268])\n",
            "logits_per torch.Size([268, 8, 88])\n",
            "logits_trans torch.Size([8, 268, 88])\n",
            "neg_logits torch.Size([8, 268, 88])\n",
            "binary_logits torch.Size([8, 268, 88, 2])\n",
            "logits_flatten torch.Size([188672, 2])\n",
            "input_sequences torch.Size([566, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 566])\n",
            "logits_per torch.Size([566, 8, 88])\n",
            "logits_trans torch.Size([8, 566, 88])\n",
            "neg_logits torch.Size([8, 566, 88])\n",
            "binary_logits torch.Size([8, 566, 88, 2])\n",
            "logits_flatten torch.Size([398464, 2])\n",
            "input_sequences torch.Size([214, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 214])\n",
            "logits_per torch.Size([214, 8, 88])\n",
            "logits_trans torch.Size([8, 214, 88])\n",
            "neg_logits torch.Size([8, 214, 88])\n",
            "binary_logits torch.Size([8, 214, 88, 2])\n",
            "logits_flatten torch.Size([150656, 2])\n",
            "input_sequences torch.Size([214, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 214])\n",
            "logits_per torch.Size([214, 8, 88])\n",
            "logits_trans torch.Size([8, 214, 88])\n",
            "neg_logits torch.Size([8, 214, 88])\n",
            "binary_logits torch.Size([8, 214, 88, 2])\n",
            "logits_flatten torch.Size([150656, 2])\n",
            "input_sequences torch.Size([600, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 600])\n",
            "logits_per torch.Size([600, 8, 88])\n",
            "logits_trans torch.Size([8, 600, 88])\n",
            "neg_logits torch.Size([8, 600, 88])\n",
            "binary_logits torch.Size([8, 600, 88, 2])\n",
            "logits_flatten torch.Size([422400, 2])\n",
            "input_sequences torch.Size([319, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 319])\n",
            "logits_per torch.Size([319, 8, 88])\n",
            "logits_trans torch.Size([8, 319, 88])\n",
            "neg_logits torch.Size([8, 319, 88])\n",
            "binary_logits torch.Size([8, 319, 88, 2])\n",
            "logits_flatten torch.Size([224576, 2])\n",
            "input_sequences torch.Size([640, 8, 88])\n",
            "outputs_drop torch.Size([8, 512, 640])\n",
            "logits_per torch.Size([640, 8, 88])\n",
            "logits_trans torch.Size([8, 640, 88])\n",
            "neg_logits torch.Size([8, 640, 88])\n",
            "binary_logits torch.Size([8, 640, 88, 2])\n",
            "logits_flatten torch.Size([450560, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-fa7af15de15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrfinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-c5997674caf3>\u001b[0m in \u001b[0;36mlrfinder\u001b[0;34m(start, end, model, trainset_loader, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainset_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mctr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0506b13639f8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmidi_full_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_full_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpiano_roll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_filename_to_piano_roll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_full_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# print(\"piano_roll\",piano_roll.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0506b13639f8>\u001b[0m in \u001b[0;36mmidi_filename_to_piano_roll\u001b[0;34m(midi_filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmidi_filename_to_piano_roll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmidi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidiread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpiano_roll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpiano_roll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/midi/midi_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, r, dt)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpiano_roll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpiano_roll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mabs_time_in_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voBsVhPX7RWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2eac33bb-2ed9-4362-cebf-64eb7bff55bf"
      },
      "source": [
        "plt.plot(lrs[:15], losses[:15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6cc57c3c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXic1X0v8O9vNo1Gy4w0kqzRYm02MTYYg4UXGZKUkCeQEmgvpCEkLAmU0ixNutyWtL1pktvbe7s8TW/i3AQHuE1CbqGlCXEa0pQUAhhLxrKxMcZgS/KqkW1to3VGmuXcP2ZeSR5LmtHM+84ifT/PM49neTVz9Nr66vi853eOKKVARET5z5TtBhARkT4Y6EREywQDnYhomWCgExEtEwx0IqJlgoFORLRMWBIdICJ2AK8AKIgd/6xS6i/ijnkAwN8C6I09tVMp9fhi71tRUaEaGxtTaDIR0cp14MCBAaVU5XyvJQx0AFMAblJKjYuIFcAeEfm5Uqoj7rhnlFKfS7ZRjY2N6OzsTPZwIiICICKnF3otYaCraOXReOyhNXZjNRIRUY5JagxdRMwicgjARQAvKKX2zXPYnSLypog8KyL1uraSiIgSSirQlVJhpdQmAHUAtojIVXGH/BRAo1JqI4AXAHxvvvcRkYdFpFNEOvv7+9NpNxERxVnSLBellA/ASwBuiXt+UCk1FXv4OIDNC3z9LqVUq1KqtbJy3jF9IiJKUcJAF5FKEXHF7hcC+CCAd+KO8cx5eDuAY3o2koiIEktmlosHwPdExIzoL4B/Vkr9m4h8DUCnUmo3gN8TkdsBhAAMAXjAqAYTEdH8JFvL57a2tipOWyQiWhoROaCUap3vNVaKEmXAyGQQPznUm/hAojQw0Iky4F8OnMUXnj6EXp8/202hZYyBTpQB54ajQe5loJOBGOhEGaAFOQOdjMRAJ8oA70g0yPtGAlluCS1nDHSiDPD6okHexx46GYiBTmQw/3QYQxPTAAAve+hkIAY6kcG04RYAOM9AJwMx0IkMpl0Iba4sQt8Ih1zIOAx0IoNpgd7aUIaB8WlMhcJZbhEtVwx0IoP1+gIQAa5dXQaAwy5kHAY6kcF6h/1YVWJHfZkDwOyMFyK9MdCJDOb1+VFbVgiPyw4AOD/KcXQyBgOdyGDeET9qXIWocRZGH7OHTgZhoBMZKBJR6PMFUOOyo9Bmhsth5UwXMgwDnchAAxNTmA5HUOuK9s49zkL0sYdOBmGgExlIG17Rhls8TjurRckwDHQiA2lz0Gtcs4F+nkMuZBAGOpGBtEDXhlxqXIUYngzCP83iItIfA53IQL0+P4psZpQWRvdj9zijUxd5YZSMwEAnMpDXF52yKCIAohdFAa6LTsZgoBMZyOsLzIyfA7M9dO5cREZIGOgiYheR10XksIgcFZGvznNMgYg8IyJdIrJPRBqNaCxRvtF66JrqWKBzPRcyQjI99CkANymlrgGwCcAtIrIt7pgHAQwrpdYA+DqAv9a3mUT5JxAMY3BiGrWxkn8AsFvNcBfZOHWRDJEw0FXUeOyhNXZTcYfdAeB7sfvPAviAaIOGRCtU/JRFjcdl50VRMkRSY+giYhaRQwAuAnhBKbUv7pBaAGcBQCkVAjACwD3P+zwsIp0i0tnf359ey4lyXO9Cgc5qUTJIUoGulAorpTYBqAOwRUSuSuXDlFK7lFKtSqnWysrKVN6CKG/Ez0HXeJzsoZMxljTLRSnlA/ASgFviXuoFUA8AImIB4AQwqEcDifKVtrGFdiFU43EWYjQQwsRUKEsto+UqmVkulSLiit0vBPBBAO/EHbYbwP2x+3cBeFEpFT/OTrSieH3RjS2s5kt/zGpcLC4iYyTTQ/cAeElE3gSwH9Ex9H8Tka+JyO2xY54A4BaRLgB/AOBRY5pLlD+iUxbtlz3v4broZBBLogOUUm8CuHae5788534AwEf1bRpRfvP6/Liq1nnZ8yz/J6OwUpTIAJGIgnckcNkFUQBYVWqHCMv/SX8MdCIDDE5MYzoUuWzKIgDYLCZUFBdw6iLpjoFOZICFioo0NU47vBxyIZ0x0IkMMBvol18UBWLFRRxyIZ0x0IkM0LtAUZGm2mlHn88Pzu4lPTHQiQzg9QXgsJnhLLTO+3qNy46J6TDGWFxEOmKgExkgfmOLeDMbXfDCKOmIgU5kAO+If8ELosDs2DovjJKeGOhEBvD6/Jesgx6PPXQyAgOdSGeBYBgD49MLXhAFgKqSApiE1aKkLwY6kc4SzUEHAIvZhKoSO6cukq4Y6EQ60xbdWizQAe5cRPpjoBPpbKGNLeLVcOci0hkDnUhnvT4/RKKLcC3GEyv/Z3ER6YWBTqQzr8+PqpIC2CyL/3hVO+0IBCPwTQYz1DJa7hjoRDpLNAddox3DC6OkFwY6kc68vkBSgc6NLkhvDHQiHSml0OvzJ7wgCsz20L3soZNOGOhEOprZ2MK5+AVRAKgoLoDFJOjzsYdO+mCgE+komaIijdkkWFVqx3n20EknDHQiHS0l0IHZqYtEekgY6CJSLyIvicjbInJURL4wzzHvF5ERETkUu33ZmOYS5bbeWKFQMmPoAOBxceci0o8liWNCAP5QKXVQREoAHBCRF5RSb8cd96pS6jb9m0iUP7w+PwqtZrgc829sEa/GaccvjgaglFpw7XSiZCXsoSul+pRSB2P3xwAcA1BrdMOI8lHvsB+1ZQtvbBHP47RjOhTB4MS0wS2jlWBJY+gi0gjgWgD75nl5u4gcFpGfi8gGHdpGlHeSLSrSVMfWReeFUdJD0oEuIsUA/hXAF5VSo3EvHwTQoJS6BsA3ATy3wHs8LCKdItLZ39+fapuJclaijS3izexcxKmLpIOkAl1ErIiG+Q+VUj+Kf10pNaqUGo/dfx6AVUQq5jlul1KqVSnVWllZmWbTiXKLtrFFjTP5HvrMzkXsoZMOkpnlIgCeAHBMKfX3CxxTHTsOIrIl9r6DejaUKNdpobyUIRd3kQ02s4lTF0kXycxy2QHgXgBHRORQ7Lk/BbAaAJRS3wFwF4DfFZEQAD+AuxXXBKUVZqlz0AHAZBJUO+1cF510kTDQlVJ7ACx6yV4ptRPATr0aRZSPepPc2CJetZPVoqQPVooS6cSrbWzhLFjS19WwWpR0wkAn0onX50dlcQEKLOYlfZ3HVYgLowFEIhylpPQw0Il0kuw66PFqnHYEwwoD41MGtIpWEgY6kU68Sa6DHk8rLuK66JQuBjqRDrSNLWqWUFSk0XYuOs9xdEoTA51IB0MT05gKRVIbctF2LuLURUoTA51IB1oYpxLoZQ4rCiwm7i1KaWOgE+kg1TnoACAiqHEVcgyd0sZAJ9JBOoEOANWldu4tSmljoBPpYKkbW8TzuFgtSuljoBPpwBub4ZLqrkM1zkJcGJtCmMVFlAYGOpEOooGe2nALEO2hhyMKF8fYS6fUMdCJdNDrC6Q8fg5gZg11Tl2kdDDQidIU3dhiKq0eevVMcREDnVLHQCdK0/kUNraIVzOzcxFnulDqGOhEaZrd2GLpZf+a0kILHDYzh1woLQx0ojSlOwcdiBYXeZx29tApLQx0ojRpvWptHDxVrBaldDHQidLk9flRWbL0jS3iVZfaueIipYWBTpQm70h6c9A1HlchLo5NIRiO6NAqWokY6ERp6vX5UadDoNc47VAKuDDKYRdKDQOdKA1KqZmy/3R5XNrURQY6pSZhoItIvYi8JCJvi8hREfnCPMeIiHxDRLpE5E0Ruc6Y5hLlluHJIALB1Da2iFcTu6jq5aqLlCJLEseEAPyhUuqgiJQAOCAiLyil3p5zzK0A1sZuWwF8O/Yn0bLWO6zNQU8/0FktSulK2ENXSvUppQ7G7o8BOAagNu6wOwB8X0V1AHCJiEf31hLlGD3moGtK7FaUFFg45EIpW9IYuog0ArgWwL64l2oBnJ3z+BwuD32IyMMi0ikinf39/UtrKVEOmq0STT/QgeiqixxyoVQlHegiUgzgXwF8USk1msqHKaV2KaValVKtlZWVqbwFUU7x+vywW00oS3Fji3geZyF76JSypAJdRKyIhvkPlVI/mueQXgD1cx7XxZ4jg+w5MYBAMJztZqx42hz0VDe2iFfjYvk/pS6ZWS4C4AkAx5RSf7/AYbsB3Beb7bINwIhSqk/HdtIcxy+M4ZNP7MNTHaez3ZQVL9110ONVlxZiYHwaUyH+sqalS6aHvgPAvQBuEpFDsduHReQREXkkdszzAHoAdAH4LoDPGNNcAoC9XQMAgD2xPyl7vD7/zNK3evDE5rNfGJnS7T1p5Ug4bVEptQfAov+fVEopAJ/Vq1G0uPaeQQDA6yeHEAxHYDWzPiwbpkJh9I+lt7FFvJmdi0b8WO126Pa+tDIwCfJMJKKw7+QQKksKMDkdxuGzvmw3acWa3dgi/SpRjdZD5zg6pYKBnmfevTAG32QQj7yvBSLA3u7BbDdpxdJzDrrGM1MtypkutHQM9DzTHgvwD21YhQ01pXiN4+hZo4WunkMuDpsFzkIrq0UpJQz0PNPRM4j68kLUlTmwo6UCb5zxwT/NGRHZoBUAeXQccgHAnYsoZQz0PKKNn29vdgMAtre4MR2OoPP0UJZbtjLptbFFvBpXIYdcKCUM9Dxy7PwoRvxBbIsF+pamcljNgte6OI6eDb0+fTa2iMceOqWKgZ5HOnqiPXEt0B02C66tL0N7N8fRs6HX50etzsMtQDTQo8vyciiNloaBnkfauwfR4HZc0ivc3uLGkd4RjPiDWWzZyjOzsYWORUUaj5MbXVBqGOh5IhxReP3kILY1uS95fseaCkQUsK+Hwy6ZpOfGFvFm5qJz1UVaIgZ6njjWN4rRQAjbWy4N9E31LhRazZyPnmF6L5s712y1KHvotDQM9DzREeuBa+PnGpvFhOubyrGX4+gZZURRkUbbuYg9dFoqBnqe6OgZRFNF0cwP+1xtLW4cvzCOi2Ps0WXKbA9d/4uidqsZ5UU29I3y75OWhoGeB8Kx+efbmsvnfX1HSwWA2SpSMp7X50eBxYTyIpsh7+9x2tlDpyVjoOeBt72jGAuELhtu0ayvKUWp3YK9nI+eMd7YOuh6bWwRjzsXUSoY6HmgvSc6Pr5QoJtNgu0tbrzGcfSMMaqoSFPDvUUpBQz0PNDRM4TmiiKsKl14vHbHmgqcG/bj7NBkBlu2cnl9fkPGzzUeZyFGAyFMTIUM+wxafhjoOS4UjmD/ySFsa5m/d65pi73O1ReNNxUK46LOG1vE05bR5bALLQUDPccd9Y5ibGrh8XNNS2UxqkoKOB89A7Tt4YyYsqiZDXQOu1DyGOg5bnb++fwzXDQigrYWN/Z2DyK6IyAZxcg56Bqt99/HVRdpCRjoOa69ZxAtlUWoKkk8Xtu2pgID41M4fmE8Ay1buYysEtWsKrVDJLq3KFGyGOg5bGb8PMFwi0YbR2fVqLG0QJ+vyEsvNosJFcUF7KHTkiQMdBF5UkQuishbC7z+fhEZEZFDsduX9W/myvSWdxQT0+HL1m9ZSF2ZAw1uB9dHN1ivz4+K4gLYrfpubBHP47SzWpSWJJke+j8CuCXBMa8qpTbFbl9Lv1kEzFZ+bm1KLtCBaC99X88gQuGIUc1a8YxaBz0eq0VpqRIGulLqFQDc4ywLOnoGsbaqGJUlBUl/TVtLBcamQnjLO2pgy1Y2r8FFRRpWi9JS6TWGvl1EDovIz0Vkw0IHicjDItIpIp39/f06ffTyFAxHsP9U8uPnmu0cRzdUdGOLQEYCvcZlx/hUCKMBbl5CydEj0A8CaFBKXQPgmwCeW+hApdQupVSrUqq1srJSh49evo70jmByOrzkQK8oLsC66hKu62IQ32QQ/mA4Yz10gFMXKXlpB7pSalQpNR67/zwAq4hUpN2yFU6bf741wfzz+bS1VGD/qSFMhbgnpd5m56BnZgwdYHERJS/tQBeRaoktOSciW2Lvye5hmtq7B3HFqmJUFCc/fq5pa3FjKhTBwdM+A1q2smViDrrG4+LeorQ0lkQHiMg/AXg/gAoROQfgLwBYAUAp9R0AdwH4XREJAfADuFuxVDEtwXAEnaeG8VutdSl9/dbmcphNgr3dA0lPeaTkZDLQV5UUwCTcuYiSlzDQlVIfT/D6TgA7dWtRAhdHAzh4ZhhX1ToNXY86m94854M/uPTxc02J3Yqra53Y2z2IP9S5bSuddyQAm8UEt0EbW8xlMZtQVWLn3qKUtISBnmv2dA3gD/75MACgvMiGq2qd2FjrjP5Z54THac/7kO/oic4S3ZpioAPAjjVuPPZyD8anQiguyLu/5pwVnYOeuY6Ex2XHeQY6JSnvftI/fLUHzZXFOHLOhyO9I3jz3Ai+3TWAcCQ6yuMusuHqOieuro3d6pyoLs2vkO/oGcS66pK0tjdra6nAt17qxv6TQ/i1dVU6tm5l88YCPVM8TjveOT+Wsc+j/JZ3gW63mrGp3oVN9a6Z5wLBMN7uG8VbsYB/q3cErxzvRyzjUVFcgKtrS3F1nQtXx3ryi20WkU3Toej4+ceur0/rfTY3lMFmMeG1rgEGuo68Pj/ed0Xmptx6nIV46Z1+KKXyqlNC2ZF3gT4fu9WM61aX4brVZTPP+aejIR/tyY/iSK8PL88J+cqSgtlefCzkq3Ig5NMdP9fYrWa0NpRxfXQdTYcihm9sEc/jtMMfDGPEH4TLYfy4PeW3ZRHo8ym0mbG5oQybG2ZDfnI6hGN9o3jz3AiO9I7gyLkR/OrdizMhv2ONGz/49FaYTNnrCbV3D0IE2Nq09Pnn8dpa3Pi7/ziOoYlpw3anX0kujAagVGZmuGi0z/L6Agx0SmjZBvp8HDYLNjeUY3PDbFhOTIXwdt8ofn7kPJ587SRePt6f1SGKjpODWFddijIdArhtTQXwH8fR3j2IX9/o0aF1K9u5YeM3toinFRedH/VjfU1pxj6X8tOKXw+9qMCC6xvL8eit67CqtABP7DmZtbZMhcI4cHo44e5EydpY60RxgYXruugkk3PQNVr5v5fl/5SEFR/oGpvFhPvbGrGnawDH+rKzUuHhsyMIBCNpj59rLGYTtjaVcxxdJ1qgewzc2CJeZUkBLCZh+T8lhYE+xz1bVqPQas5aL72jR7/xc832FjdODkzMhBGlzjviR0WxzfCNLeYymwSrSu1coIuSwkCfw+Ww4aOtddh9yIuLY5n/AWrvHsSV1aW6XvzasSa6Thp76enrzdCyufE8Tjv3FqWkMNDjfGpHE4KRCJ5qP53Rzw0Ewzh4Zlj3tVfesypaoMRx9PR5fX7UODMf6NVOVotSchjocZoqivCBdavw1L4zCAQzt/zs4bM+TIX0Gz/XmEyC7S1u7O0aBNdMS110Y4vM7FQUr8YV3bmIf3+UCAN9Hg/d2IShiWn8+I3ejH1me2z8fIuO4+eaHS0VOD8awMmBCd3fe6UY8QcxOR1GTQbWQY/ncdoxFYpgaGI6459N+YWBPo+tTeXYUFOKJ/acRCSSmV5RR88gNtSUwllo1f2922LDOK9xHD1lsxtbZGMMneuiU3IY6PMQETx0YxO6Lo7j5RPG730aHT/3YVuTMWuXN7gdqHUVYm8Xx9FTpc0Dz86Qiz3WBl4YpcUx0Bfw61fXRAuNXjV+CuMbZ3yYDkUM24xCJDqO3t4zmLH/cSw3WpjWlmXnoigAnB9lD50Wx0BfgM1iwn3bo4VG75w3ttCoo2cQJgGuN2D8XLNjjRu+ySDezlLRVL7z+vwZ29giXkVRAaxmYbUoJcRAX8QntsYKjQzupbf3DOKqWidK7fqPn2vaWqLz0ds5jp6STG9sMZfJJKh22lktSgkx0Bfhcthw1+Y6/MTAQqNAMIxDZ3y6T1eMt6rUjpbKIrzG+egpiU5ZzN7yyh5nIatFKSEGegKf2tGI6XAET3WcMeT9D54exnQ4otuCXItpa6nA6yeHEAxHDP+s5cbrC2SlqEhTw2pRSgIDPYHmymLcfGUVnuo4bUih0cz4eaPxgb5jjRuT02EcPusz/LOWk+lQBBfGslP2r6l2FuLCaIAXtWlRDPQkPHhDs2GFRh09Q7i61okSA8fPNdua3RDhui5LpW1skY056Joalx3BsMLAxFTW2kC5L2Ggi8iTInJRRN5a4HURkW+ISJeIvCki1+nfzOza1jxbaKRn+bV/Oow3zg5jm0HTFeO5HDZsqCnFa5yPviS9WVgHPd5McRHH0WkRyfTQ/xHALYu8fiuAtbHbwwC+nX6zcouI4MEbYoVGx/UrNDp4ZhjBsDL8guhcO1oq8MYZH/zTmVunJt/NbmyRzYui0c/mTBdaTMJAV0q9AmBokUPuAPB9FdUBwCUiy26/s9s21qCqRN8djdq7B2E2SUbGzzXbW9yYDkfQeXqxv1KaKxs7FcXTPpvl/7QYPcbQawGcnfP4XOy5y4jIwyLSKSKd/f3Gl9TrSdvR6NUTA3j3/Jgu79nRM4irY9vEZcqWpnJYTILXujiOnqxeXwDuosxubBGvzGFFgcXEQKdFZfSiqFJql1KqVSnVWllZmcmP1sUntq6G3WrCE3t60n6vyekQDp8zfv55PIfNgmtXu9DO+ehJy9ayuXOJSHSjC67nQovQI9B7AdTPeVwXe27Z0QqNnnvDi/6x9GYbHDgdHT83av2WxbS1VOBI7whG/MGMf3Y+ynZRkcbjLGQPnRalR6DvBnBfbLbLNgAjSqk+Hd43J316R1Os0Ci9HY06egZhMQlaG8p0alny2lrciChgXw+HXRLJ5sYW8TwuO/rYQ6dFJDNt8Z8AtAN4j4icE5EHReQREXkkdsjzAHoAdAH4LoDPGNbaHNBcWYwPrEu/0Ki9exAb65woyuD4ueba1WWwW02cj56EUX8IE9PhrM5B19Q4C3FhbAphFhfRAhKmiVLq4wleVwA+q1uL8sCDNzbhnu/uw3Nv9OLuLauX/PUTUyG8eW4ED7+32YDWJWazmHB9YznnoychmxtbxKt22hGOKPSPTc0sqUs0FytFU7C92Y31ntQLjQ6cHkYoktn55/F2rKnAiYvjhi06tlzkwpRFzcxGF5yLTgtgoKdAKzQ6cXEcr5xYei+3XRs/b8z8+LlmB5fTTYoWnrkQ6KwWpUQY6Cn6yDXRQqPHX136FMaOnkFcU++Cw5b58XPN+ppSlNot2Mv56IvqzeLGFvFqZvYWZQ+d5sdAT1GqhUbjsfHz7VkcbgEAsym6LR3XR19cdNlcO0ymzG9sEa+00AKHzcypi7QgBnoa7tkSLTR6cgnLAXSeGkI4y+PnmraWCpwb9uPs0GS2m5Kzeocnc2K4BYgO9XHnIloMAz0NZUU23HldHX58qBcD48kVGnX0DMFqFmzOwvzzeDvWRH+pcLbLwry+7K6DHq/GWci9RWlBDPQ0ffqGJkyHki80au8ZxKZ6Fwpt2VsXRNNSWYyqkgLOR19AMJz9jS3iedhDp0Uw0NPUEis0+kF74kKjsUAQb/WO5MRwCxD9L3xbixt7uwd1Xed9uTg/om1skTtzvj2uQlwcm+I2gjQvBroOHryhCYMT0/jJocWXsOk8NYxwRGX9guhcbS0VGBifwvEL49luSs7JpTnomhqnHUoBF9NcS4iWJwa6Dra3uHFlEoVGHT2DsJlNuC4Hxs81bbFx9L2c7XKZXJqDrtEqRLmmC82Hga4DEcFDNzTh+IVxvLpIoVFHzyA2rXZldV3teHVlDjS4HVwffR7axUdt/ncu0H65eDl1kebBQNfJR66pQWVJAR5fYArjaCCIIzk0fj5XW4sb+3oGEeK47CV6fX6UF9ly4gK2xsMeOi2Cga4Tm8WE+7c34JXj/Th+4fJCo85TQ4io6IbTuaatpQJjUyG85R3NdlNyitfnz4lFueYqsVtRUmBhcRHNi4Guo3u2NixYaNTePQibxYTrVufO+LlG22SD4+iXypWNLeKxuIgWwkDXUXmRDf/lujr86I3LC406eoZwbX1ujZ9rKooLsK66hOu6zKGUQu9wbmxsEc/j4s5FND8Gus4+vSNaaPTDjjMzz434gzjqHcnKdnPJ2t7ixv5TQ2lt2rGcjAZyZ2OLeDVOO6tFaV4MdJ2tqSrGTeuq8IOOUzPhuP+kNn6eu4G+o6UCU6EI3jjjy3ZTckIuzkHXeJyFGBifwlSIv3zpUgx0Azx4QxMGxqex+5AXQHS6YoHFhE31riy3bGFbmsthEo6ja3I60GPj+hdHWVxEl2KgG6CtxY111SUzhUbtPYO4bnVZTo6fa0rtVmysc3Fdl5jemUDPvYui2tRFL6cuUhwGugFEBA/d2Ix3L4zhZ0f68HbfaE4Pt2h2rHHj0FkfZ1AgtrGF2YSKooJsN+UyMzsX8cIoxWGgG+Qj13hQWVKAP3/uLSiFnL4gqvnNa+tQaDXjk4/vS3o54OXK6wvA48qNjS3icW9RWkhSgS4it4jIuyLSJSKPzvP6AyLSLyKHYreH9G9qfimwmHHftgb4JoMosJhwTb0z201KaE1VMZ584Hr0+vz45OP74JucznaTssbr8+dUyf9cDpsFzkIr9xalyyQMdBExA/gWgFsBrAfwcRFZP8+hzyilNsVuj+vczrz0iW0NKLCYsLmhDAWW3B0/n2tLUzm+e18revoncP+Tr2MsEMx2k7IiWlSUm4EOaOuiM9DpUsn00LcA6FJK9SilpgE8DeAOY5u1PJQX2bDrvlb8t9vm+/2Xu25cW4n/84nrcNQ7igf/sROT06FsNymjguEILowGcmod9Hjc6ILmk0yg1wI4O+fxudhz8e4UkTdF5FkRqZ/vjUTkYRHpFJHO/v7+FJqbf953RSWu9JRmuxlLdvP6VfiHuzeh8/QQfucHB1ZUwdGF0QAiKjenLGpYLUrz0eui6E8BNCqlNgJ4AcD35jtIKbVLKdWqlGqtrKzU6aPJKLdtrMHf3HUNXj0xgM/9v4MrZpecmWVzczjQa5x2DE1Mr6hftJRYMoHeC2Buj7su9twMpdSgUkqbFvE4gM36NI+y7a7Ndfjvd2zAL49dxO8/cwjhyPLfqk6b311blruBzqmLNJ9kAn0/gLUi0iQiNgB3A9g99wAR8cx5eDuAY/o1kbLt3u2N+NMPr8O/vdmHP/nXNxFZ5qE+U1SUo7NcgNlqUY6j01yWRD3dtUcAAAztSURBVAcopUIi8jkAvwBgBvCkUuqoiHwNQKdSajeA3xOR2wGEAAwBeMDANlMWPPzeFkxMhfG///MEHDYzvnr7Bojk3hxtPXhzcGOLeDM9dE5dpDkSBjoAKKWeB/B83HNfnnP/SwC+pG/TKNd88ea18AfD2PVKDwptZjx6y7qshXpP/zi+/ssTGAsE0VJZHLsVobmyGBXFtrTalavroM81s3MRe+g0R1KBTgRElzT40q3r4J8O47GXe+CwWvCFm9dmtA3jUyF888UTeHLPSdgtZtSVO9DRM4hAcPaCbandgpaqaMg3VxbNBH6D2wGrOfEoo9cXQIPbYeS3kTa71YzyIhv3FqVLMNBpSUQEX719A/zBML7+y+Nw2Mz47fc2G/65kYjCc4d68T9//g76x6bw0c11+ONb1qGypACRiIJ3xI/u/gn09I+ju38c3Rcn8Mrxfjx74NzMe1hMgtVuB5oritFSVXRJz97lsM0c5/X582KpBo/Tnld7i54cmMCP3+hFqd2CujIHVpc7UF9eiBK7NdtNWzYY6LRkJpPgr+/cCH8wjP/x/DHYbWbcu63BsM9785wPX9l9FAfP+HBNvQvfva/1kqWITSZBXZkDdWUOvO+KS6fDjgWC6OmfiIZ8//jM/VeO92N6zjRMd5Ftphc/NhXKyY0t4nmchTg3PJntZiR04sIYdr7UhZ8e9mK+6+nlRTbUlxWivlwL+eifq8sd8DjtsCTxvyqKYqBTSswmwT98bBOmgmH8t+feQqHVjLs21+n6GQPjU/i7X7yLZzrPwl1UgL+9ayPuvK5uSQtmldituKbehWvi1qIPhSM4N+xHz0C0N68F/ovvXAQAbKjJ/WIwj9OO/aeGst2MBR31jmDni13496PnUWg146Ebm/HQjU2wmU04MzSJs0N+nBmaxJmhSZwbnsSR3hH8+1vnEZqT+maToMZlnwn4+nIH6stmA9/lsC7bi/OpYKBTyqxmE3becx1++/ud+ONnD8NuNeG2jTVpv28wHMEP2k/j6788Dv90GA/d0ITPf2AtSnX8r7nFbEJjRREaK4pw07pLX5sKhfNi7R2Py44RfxCT0yE4bLnzo3zorA87XzyBXx67iJICCz77/jX49A1NKC+aHdZyOWzYWHf5hi+hcATnRwOxwL809F94+wIGxi9dMK64wIL6cgeaK4qwpakcbS1urKkqXrEhnzv/Cigv2a1mPHbvZtz/5Ov44tOHYLeYcfP6VSm/354TA/jqT4/ixMVxvPeKSnz5tvVYU1WsY4sTy4cwB2bnyXt9gYyfo/nsPzWEb/znCbx6YgAuhxV/8MErcH9bI5yFyf8itphNM8NnaLn89YmpEM4Ozwb92djt0FkffnakD0B00/PtLW5sb3Zje4sbjW7Higl4BjqlzWGz4MkHrscnH9+Hz/zwIJ584HrcsLZiSe9xdmgSf/mzt/GLoxewutyBx+9rxQeurFoxP4ipmDt1MVuBrpTC3u5BfOM/T2DfySFUFNvw6K3r8MltDSgu0D9eigosWFddinXVlw6JKaVwdsiP9p4BtHcPYm/3IH56OLoFZHWpHW0tbmyLhXx9eW7PYEoHA510UWK34nuf3oK7d3Xgt7/fie8/uAXXN5Yn/Dr/dBjf/lUXvvNKD8wi+K8feg8evKEpp7fryxXaWjPZKP9XSuFX7/bjmy+ewMEzPqwqLcCXb1uPj29ZnZWCLJHoDKbV7tX42PWroZRCz8AE2rsH0d49iJeP9+NHb0RXLKkvL5zpvW9vrkC1M7drDpaCgU66cTlseOqhrfitx9rxqf+7Hz98aOtlFyM1Sin87Egf/upnx+AdCeCOTTV49NZ1MxWQlFhVaXR7vExWi0YiCv/x9gXsfOkE3uodRa2rEH/5G1fhrs11OfVLWERmpqV+clsDlFI4fmEce7ujPfhfHL2Af+6MTmltrijCthZ3tBff7EZFce5tO5gsUSo763K0traqzs7OrHw2Gev8SAAffWwvRv0hPP3wtsuWDz7WN4qv7D6KfSeHsN5Tiq/cvgFbmhL35ulyrX/5S9x8ZRX+150bDf2ccETh+SN92PliF969MIYGtwOfff8a/OZ1tUkVa+WacEThWN9otAffM4jXTw5hfCq67v8Vq4rR1lKBbc1ubGsuv6RGIReIyAGlVOu8rzHQyQhnhybxW4+1IxiO4OmHt2NNVTF8k9P4+xeO46mO03AWWvFHH3oP7r5+Ncw5uG9nvrh95x4UWEz427uuQYndgmK7RdeLuqFwBD855MW3ftWFnv4JrKkqxud+bQ1u2+hZVvPDQ+EIjvSOoL0nOkSz/9TQTPXxuuoSbG0qx9ZmN65vLEdlSXZ78Ax0yoru/nF87LF2WEwmfGpHI779cjdG/UHcu60Bv//BK3Ku55OPPv9Pb8xc/NPYLCaU2i0oLrCgxG6NBv2c+9qtuODSxyV2a+w4C2wWE350sBff/lU3zgxN4kpPKT5/0xrcsqE6JzfO1ttUKIzDZ0ewr2cQ+04O4cDpYfhja8+3VBZhS1O09761yZ3xMXgGOmXNO+dHcfeuDvgmg9jWXI6/+MiGvNzBKVcNTUyj81R0uGAsEML4VAijgWD0fiCEMe1+7PWxQBDjU6F5Kzbns7HOic/ftBY3r/AZR8FYD/71k0PY1zOIzlPDGIsN0awud8z04Lc2laOurNDQc8VAp6zqujiOs0OTeP97Kld0KOQKpRQmpsMzgT86E/izvwjGp0LY3FCGG9dW8O9sHtoYfEesB7//1BB8k9EN1WucdmyZE/BNFUW6nkMGOhGRgSIRheMXx2I9+CHsOzk4U9VaWVKALU3l2NZUji1NbqytKk5r2IqBTkSUQdo8+H09Q3j9ZLQXr9ULlDms+OyvrcFDN6a2Suligc556EREOps7D/6eratnKln3xcK9qtSYC6kMdCIig81Wsjrw0dZ6wz5n+UwkJSJa4RjoRETLBAOdiGiZSCrQReQWEXlXRLpE5NF5Xi8QkWdir+8TkUa9G0pERItLGOgiYgbwLQC3AlgP4OMisj7usAcBDCul1gD4OoC/1ruhRES0uGR66FsAdCmlepRS0wCeBnBH3DF3APhe7P6zAD4gLC8jIsqoZAK9FsDZOY/PxZ6b9xilVAjACAC3Hg0kIqLkZPSiqIg8LCKdItLZ39+fyY8mIlr2kiks6gUwdyZ8Xey5+Y45JyIWAE4Ag/FvpJTaBWAXAIhIv4icTqXRACoADKT4tSsJz1NyeJ6Sx3OVHCPPU8NCLyQT6PsBrBWRJkSD+24A98QdsxvA/QDaAdwF4EWVYJEYpVRlEp89LxHpXGgtA5rF85Qcnqfk8VwlJ1vnKWGgK6VCIvI5AL8AYAbwpFLqqIh8DUCnUmo3gCcA/EBEugAMIRr6RESUQUmt5aKUeh7A83HPfXnO/QCAj+rbNCIiWop8rRTdle0G5Amep+TwPCWP5yo5WTlPWVsPnYiI9JWvPXQiIoqTU4GezpoxIvKl2PPvisiHMtnubEj1XImIW0ReEpFxEdmZ6XZnWhrn6YMickBEjsT+vCnTbc+kNM7TFhE5FLsdFpHfzHTbMy3dta1EZHXs5++PdG+cUionbojOoOkG0AzABuAwgPVxx3wGwHdi9+8G8Ezs/vrY8QUAmmLvY87295Sj56oIwA0AHgGwM9vfSw6fp2sB1MTuXwWgN9vfT46eJwcAS+y+B8BF7fFyvKVzrua8/iyAfwHwR3q3L5d66OmsGXMHgKeVUlNKqZMAumLvt1ylfK6UUhNKqT0AAplrbtakc57eUEp5Y88fBVAoIgUZaXXmpXOeJlV0uQ8AsANY7hfl0lrbSkR+A8BJRP9N6S6XAj2dNWOS+drlhOvrJEev83QngINKqSmD2pltaZ0nEdkqIkcBHAHwyJyAX45SPlciUgzgTwB81ajG5VKgE+UcEdmA6HLQv5PttuQqpdQ+pdQGANcD+JKIGLMDcv77CoCvK6XGjfqAXAr0pawZg7g1Y5L52uUknXO1kqR1nkSkDsCPAdynlOo2vLXZo8u/J6XUMQDjiF5zWK7SOVdbAfyNiJwC8EUAfxqrwtdNLgX6zJoxImJD9GLC7rhjtDVjgEvXjNkN4O7Y1eUmAGsBvJ6hdmdDOudqJUn5PImIC8DPADyqlHotYy3OjnTOU1MstCAiDQDWATiVmWZnRcrnSil1o1KqUSnVCOAfAPyVUkrfmWbZvmocd/X3wwCOI3oV+c9iz30NwO2x+3ZErw53IRrYzXO+9s9iX/cugFuz/b3k+Lk6heiaO+OIjgGuz3T7c/08AfhzABMADs25VWX7+8nB83Qvohf4DgE4COA3sv295Oq5inuPr8CAWS6sFCUiWiZyaciFiIjSwEAnIlomGOhERMsEA52IaJlgoBMRLRMMdCKiZYKBTkS0TDDQiYiWif8PTyCPDtxnRP4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_T6riVS7g3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8e1e9876-2a41-4a68-c7da-7cf70e46b2c8"
      },
      "source": [
        "def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
        "    iterations = mini_batches\n",
        "    lr_mid = lr_high/7 + lr_low\n",
        "    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
        "    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
        "    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
        "    return np.hstack([up, down[1:], floor])\n",
        " \n",
        "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
        "plt.plot(lrs_triangular)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f747261da90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPu-El-7kXb"
      },
      "source": [
        "clip = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0r_dFu27k4m"
      },
      "source": [
        "def train_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n",
        "    loss_list = []\n",
        "    val_list =[]\n",
        "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
        "    for epoch_number in range(epochs_number):\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "        for lr, batch in zip(lrs_triangular, trainset_loader):\n",
        "            optimizer.param_groups[0]['lr'] = lr\n",
        " \n",
        "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "            # print( \"input_sequences_batch, output_sequences_batch, sequences_lengths\", input_sequences_batch.shape, output_sequences_batch.shape, len(sequences_lengths))\n",
        " \n",
        "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
        " \n",
        "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
        "            # print(input_sequences_batch_var.shape)\n",
        " \n",
        "            optimizer.zero_grad()\n",
        " \n",
        "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
        "            # print(\"output\",output_sequences_batch_var.shape)\n",
        " \n",
        "            loss = criterion(logits, output_sequences_batch_var)\n",
        "            loss_list.append(loss.item())\n",
        "            epoch_loss.append(loss.item())\n",
        "            loss.backward()\n",
        " \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        " \n",
        "            optimizer.step()\n",
        " \n",
        "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
        "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
        " \n",
        "        current_val_loss = validate(model)\n",
        "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
        "        print('')\n",
        " \n",
        "        val_list.append(current_val_loss)\n",
        " \n",
        "        if current_val_loss < best_val_loss:\n",
        " \n",
        "            torch.save(model.state_dict(), 'music_model_padfront_regularized.pth')\n",
        "            best_val_loss = current_val_loss\n",
        "    return best_val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GBBajtZ7paZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b8aea7-ccd5-4c1e-8ed9-ad5d70d2496a"
      },
      "source": [
        "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
        "rnn = rnn.cuda()\n",
        "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
        "best_val_loss = train_model(rnn, lrs_triangular)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: Epoch: 0 : 0.22805845234976257\n",
            "Validation Loss: Epoch: 0 : 8.319310628124921e-07\n",
            "\n",
            "Training Loss: Epoch: 1 : 0.1033986492385698\n",
            "Validation Loss: Epoch: 1 : 7.240011548704122e-07\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU8ONg5M7sIb"
      },
      "source": [
        "lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\n",
        "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNs86L37xDy"
      },
      "source": [
        "lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\n",
        "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_lWcZMz7z4A"
      },
      "source": [
        " rnn.load_state_dict(torch.load('music_model_padfront_regularized.pth',map_location = torch.device(\"cpu\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS4_Vzih73xp"
      },
      "source": [
        "# validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkjUFpiv77_I"
      },
      "source": [
        "def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n",
        " \n",
        "    if starting_sequence is None:\n",
        "                \n",
        "        current_sequence_input = torch.zeros(1, 1, 88)\n",
        "        current_sequence_input[0, 0, 40] = 1\n",
        "        current_sequence_input[0, 0, 50] = 0\n",
        "        current_sequence_input[0, 0, 56] = 0\n",
        "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
        "    else:\n",
        "        current_sequence_input = starting_sequence\n",
        "        \n",
        "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
        " \n",
        "    hidden = None\n",
        " \n",
        "    for i in range(sample_length):\n",
        " \n",
        "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
        " \n",
        "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
        " \n",
        "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
        " \n",
        "        current_sequence_input = Variable(current_sequence_input.float())\n",
        " \n",
        "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
        " \n",
        "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
        "    \n",
        "    return sampled_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmt8xlTQ783u"
      },
      "source": [
        "testset = NotesGenerationDataset('Nottingham/test/', longest_sequence_length=None)\n",
        " \n",
        "testset_loader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQlxa0D58BBH"
      },
      "source": [
        "batch = next(iter(testset_loader))\n",
        "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
        " \n",
        "# input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj2Xwxeu8Gf4"
      },
      "source": [
        "x = input_sequences_batch_var.cpu().numpy()\n",
        "plt.imshow(x.reshape((x.shape[0],88)).transpose(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A92w9wQY8MRe"
      },
      "source": [
        "rnn.cuda()\n",
        "sample = sample_from_piano_rnn(rnn, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\n",
        "io.imshow(sample)\n",
        "midiwrite('sample_reg_018.mid', sample.transpose(), dt=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pESqvK_8P6G"
      },
      "source": [
        "FileLink('sample_reg_018.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oRzeQdA8Zbk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLX3nCRP8WF3"
      },
      "source": [
        "import IPython.display as ipd\n",
        "ipd.Audio('./sample_reg_018.mp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9OCJGs90VYe"
      },
      "source": [
        "# **EXP-1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-YaCobd0bAe"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ihEe8sq0f1t"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self,ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.fc = nn.Linear(ninp,ninp)\n",
        "        # self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        # self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        # self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    # def init_weights(self):\n",
        "    #     initrange = 0.1\n",
        "    #     self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "    #     self.decoder.bias.data.zero_()\n",
        "    #     self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        # print(\"src\",src.shape)\n",
        "        # src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        # print(\"src\",src.shape)\n",
        "        src = self.pos_encoder(src)\n",
        "        # print(\"src\",src.shape)\n",
        "        output = self.transformer_encoder(src)\n",
        "        # print(\"output\",output.shape)\n",
        "        output = self.fc(output)\n",
        "        # print(\"output\",output.shape)\n",
        "        logits = output.transpose(0, 1).contiguous()\n",
        "        # print(\"logits_trans\",logits.shape)      \n",
        "        neg_logits = (1 - logits)\n",
        "        # print(\"neg_logits\",neg_logits.shape)\n",
        "        # Since the BCE loss doesn't support masking,crossentropy is used\n",
        "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
        "        # print(\"binary_logits\",binary_logits.shape)\n",
        "        logits_flatten = binary_logits.view(-1, 2)\n",
        "        # print(\"logits_flatten\",logits_flatten.shape)\n",
        "        return logits_flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKoMnVRfdVX3"
      },
      "source": [
        "# ntokens = len(TEXT.vocab.stoi) # the size of vocabulary\n",
        "emsize = 88 # embedding dimension\n",
        "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "model = TransformerModel(emsize, nhead, nhid, nlayers, dropout).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDp7b8_Gc3Lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3a88ef-1af5-45dd-9266-f873826a9232"
      },
      "source": [
        "batch = next(iter(trainset_loader))\n",
        "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "# print(\"input_sequences_batch, output_sequences_batch, sequences_lengths\", input_sequences_batch.shape, output_sequences_batch.shape, len(sequences_lengths))\n",
        " \n",
        "# output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
        "output_sequences_batch_var = output_sequences_batch.permute(1,0,2).contiguous().cuda()\n",
        "print(output_sequences_batch_var.shape)\n",
        "input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "print(input_sequences_batch_var.shape)\n",
        "  \n",
        "logits = model(input_sequences_batch_var)\n",
        "print(\"logits\",logits.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_sequences_batch, output_sequences_batch, sequences_lengths torch.Size([320, 8, 88]) torch.Size([8, 320, 88]) 8\n",
            "torch.Size([320, 8, 88])\n",
            "torch.Size([320, 8, 88])\n",
            "src torch.Size([320, 8, 88])\n",
            "src torch.Size([320, 8, 88])\n",
            "output torch.Size([320, 8, 88])\n",
            "output torch.Size([320, 8, 88])\n",
            "logits_trans torch.Size([8, 320, 88])\n",
            "neg_logits torch.Size([8, 320, 88])\n",
            "binary_logits torch.Size([8, 320, 88, 2])\n",
            "logits_flatten torch.Size([225280, 2])\n",
            "logits torch.Size([225280, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4uF3rhFEmv1"
      },
      "source": [
        "def lrfinder(start, end, model, trainset_loader, epochs=2):\n",
        "    model.train() # into training mode\n",
        "    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
        "    optimizer = torch.optim.Adam(rnn.parameters(),start)\n",
        "    loss_list = []\n",
        "    ctr = 0\n",
        "    \n",
        "    for epoch_number in range(epochs):\n",
        "        epoch_loss = []\n",
        "        for batch in trainset_loader:\n",
        "            optimizer.param_groups[0]['lr'] = lrs[ctr]\n",
        "            ctr = ctr+1\n",
        " \n",
        "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        " \n",
        "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
        " \n",
        "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
        " \n",
        "            optimizer.zero_grad()\n",
        " \n",
        "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
        " \n",
        "            loss = criterion(logits, output_sequences_batch_var)\n",
        "            loss_list.append(loss.item())\n",
        "            loss.backward()\n",
        " \n",
        "            torch.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
        " \n",
        "            optimizer.step()\n",
        "        print('Epoch %d' % epoch_number)\n",
        "    plt.plot(lrs, loss_list)\n",
        "    return lrs, loss_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6LkxxkxE6qU"
      },
      "source": [
        "def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
        "    iterations = mini_batches\n",
        "    lr_mid = lr_high/7 + lr_low\n",
        "    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
        "    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
        "    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
        "    return np.hstack([up, down[1:], floor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cK-siRM2yz"
      },
      "source": [
        "def validate(model):\n",
        "    model.eval()\n",
        "    full_val_loss = 0.0\n",
        "    overall_sequence_length = 0.0\n",
        " \n",
        "    for batch in valset_loader:\n",
        " \n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        " \n",
        "        output_sequences_batch_var = output_sequences_batch.contiguous().view(-1).cuda() \n",
        " \n",
        "        input_sequences_batch_var = input_sequences_batch.cuda() \n",
        " \n",
        "        logits = model(input_sequences_batch_var, sequences_lengths)\n",
        "        # print(\"logits\",logits.shape)\n",
        " \n",
        "        loss = criterion_val(logits, output_sequences_batch_var)\n",
        " \n",
        "        full_val_loss += loss.item()\n",
        "        overall_sequence_length += sum(sequences_lengths)\n",
        " \n",
        "    return full_val_loss / (overall_sequence_length * 88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwJWTpByFEQv"
      },
      "source": [
        "def train_model(model, lrs_triangular, epochs_number=5, wd=0.0, best_val_loss=float(\"inf\")):\n",
        "    loss_list = []\n",
        "    val_list =[]\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
        "    for epoch_number in range(epochs_number):\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "        for lr, batch in zip(lrs_triangular, trainset_loader):\n",
        "            optimizer.param_groups[0]['lr'] = lr\n",
        " \n",
        "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "            # print( \"input_sequences_batch, output_sequences_batch, sequences_lengths\", input_sequences_batch.shape, output_sequences_batch.shape, len(sequences_lengths))\n",
        " \n",
        "            output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
        " \n",
        "            input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "            # print(input_sequences_batch_var.shape)\n",
        " \n",
        "            optimizer.zero_grad()\n",
        " \n",
        "            logits = model(input_sequences_batch_var, sequences_lengths)\n",
        "            # print(\"output\",output_sequences_batch_var.shape)\n",
        " \n",
        "            loss = criterion(logits, output_sequences_batch_var)\n",
        "            loss_list.append(loss.item())\n",
        "            epoch_loss.append(loss.item())\n",
        "            loss.backward()\n",
        " \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        " \n",
        "            optimizer.step()\n",
        " \n",
        "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
        "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
        " \n",
        "        current_val_loss = validate(model)\n",
        "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
        "        print('')\n",
        " \n",
        "        val_list.append(current_val_loss)\n",
        " \n",
        "        if current_val_loss < best_val_loss:\n",
        " \n",
        "            torch.save(model.state_dict(), 'music_model_padfront_regularized.pth')\n",
        "            best_val_loss = current_val_loss\n",
        "    return best_val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJwHzKb6FMG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3ed784-e9ba-405b-c43c-e7a55208071a"
      },
      "source": [
        "emsize = 88 # embedding dimension\n",
        "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "clip = 1.0\n",
        "best_val_loss = float(\"inf\")\n",
        "model = TransformerModel(emsize, nhead, nhid, nlayers, dropout).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_val = nn.CrossEntropyLoss()\n",
        "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
        "best_val_loss = train_model(model, lrs_triangular)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: Epoch: 0 : 0.14503519808830218\n",
            "Validation Loss: Epoch: 0 : 7.517636007029678e-07\n",
            "\n",
            "Training Loss: Epoch: 1 : 0.11493732901506645\n",
            "Validation Loss: Epoch: 1 : 7.39191362876679e-07\n",
            "\n",
            "Training Loss: Epoch: 2 : 0.11418354320664738\n",
            "Validation Loss: Epoch: 2 : 7.584127456588481e-07\n",
            "\n",
            "Training Loss: Epoch: 3 : 0.11408784058551456\n",
            "Validation Loss: Epoch: 3 : 7.454765323638247e-07\n",
            "\n",
            "Training Loss: Epoch: 4 : 0.11427047597460968\n",
            "Validation Loss: Epoch: 4 : 7.44519288445025e-07\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJbjIIJFRTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af666b81-7ec4-4e36-bd9f-547213c9833a"
      },
      "source": [
        "lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\n",
        "best_val_loss = train_model(model, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: Epoch: 0 : 0.11171842583043631\n",
            "Validation Loss: Epoch: 0 : 6.552056531729898e-07\n",
            "\n",
            "Training Loss: Epoch: 1 : 0.09327773567895557\n",
            "Validation Loss: Epoch: 1 : 5.217086679354278e-07\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJG8Zp0bFeU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b88abd-1915-4985-e2e9-1e5b41ddbb71"
      },
      "source": [
        "lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\n",
        "best_val_loss = train_model(model, lrs_triangular, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: Epoch: 0 : 0.08663557417864023\n",
            "Validation Loss: Epoch: 0 : 5.18805455603513e-07\n",
            "\n",
            "Training Loss: Epoch: 1 : 0.08562649465924085\n",
            "Validation Loss: Epoch: 1 : 5.072821968429208e-07\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StR8i5y_Fik_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19943074-8792-42e3-b409-9af86d9cc28b"
      },
      "source": [
        "model.load_state_dict(torch.load('music_model_padfront_regularized.pth',map_location = torch.device(\"cpu\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuJgMrFQQnLs"
      },
      "source": [
        "def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n",
        " \n",
        "    if starting_sequence is None:\n",
        "                \n",
        "        current_sequence_input = torch.zeros(1, 1, 88)\n",
        "        current_sequence_input[0, 0, 40] = 1\n",
        "        current_sequence_input[0, 0, 50] = 0\n",
        "        current_sequence_input[0, 0, 56] = 0\n",
        "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
        "    else:\n",
        "        current_sequence_input = starting_sequence\n",
        "        \n",
        "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
        " \n",
        "    hidden = None\n",
        " \n",
        "    for i in range(sample_length):\n",
        " \n",
        "        output = rnn(current_sequence_input)\n",
        " \n",
        "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
        " \n",
        "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
        " \n",
        "        current_sequence_input = Variable(current_sequence_input.float())\n",
        " \n",
        "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
        " \n",
        "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
        "    \n",
        "    return sampled_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ugSpzFauo2"
      },
      "source": [
        "TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf8XrWGYUlz-"
      },
      "source": [
        "!cp /content/Nottingham/test/ashover_simple_chords_11.mid /content/test1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFWuKMtPZAti"
      },
      "source": [
        "os.rmdir('/content/test1/.ipynb_checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VfNEXhmQpZZ"
      },
      "source": [
        "testset = NotesGenerationDataset('/content/test1', longest_sequence_length=None)\n",
        " \n",
        "testset_loader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLcsJ1I4RGdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5428ac-c995-4224-da85-1b68d6068712"
      },
      "source": [
        "batch = next(iter(testset_loader))\n",
        "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
        " \n",
        "# input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([160, 1, 88])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL2whbjlRJwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "ed84d776-d449-4fc7-b203-83950604b526"
      },
      "source": [
        "model.cuda()\n",
        "sample = sample_from_piano_rnn(model, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\n",
        "io.imshow(sample)\n",
        "midiwrite('testing_trans.mid', sample.transpose(), dt=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmj5aaShRSns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de812d00-2511-4b29-eb05-81276985a89c"
      },
      "source": [
        "FileLink('testing_trans.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href='/content/test1/testing_trans.mid' target='_blank'>/content/test1/testing_trans.mid</a><br>"
            ],
            "text/plain": [
              "/content/test1/testing_trans.mid"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HItE4rcfepc_"
      },
      "source": [
        "# TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c02-LkbR5YIL"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cIrV_FZ-vwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd9e13f-bce3-46c2-c5ab-d7498f1cdf00"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LDprYJd-3lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16d9f20-8d25-4f2f-f6fe-c26534cbcd02"
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"spacy\"),\n",
        "                            init_token='<sos>',\n",
        "                            eos_token='<eos>',\n",
        "                            lower=True)\n",
        "train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
        "TEXT.build_vocab(train_txt)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading wikitext-2-v1.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wikitext-2-v1.zip: 100%|██████████| 4.48M/4.48M [00:00<00:00, 8.06MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80v5r75gEMEX"
      },
      "source": [
        "TEXT.build_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tomBv_17_FOR"
      },
      "source": [
        "def batchify(data, bsz):\n",
        "    data = TEXT.numericalize([data.examples[0].text])\n",
        "    # Divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_txt, batch_size)\n",
        "val_data = batchify(val_txt, eval_batch_size)\n",
        "test_data = batchify(test_txt, eval_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8DWY4rS_R1X"
      },
      "source": [
        "bptt = 35\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa0wYaXc_ZWO"
      },
      "source": [
        "ntokens = len(TEXT.vocab.stoi) # the size of vocabulary\n",
        "emsize = 200 # embedding dimension\n",
        "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmGQej5F5ftG"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxRLK2f5jJS"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84zraYdhpZ-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6dc773-1e79-4ed1-d215-c769e2781cd7"
      },
      "source": [
        "test = TransformerModel( emsize, nhead, nhid, nlayers, dropout)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=88, out_features=88, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=88, out_features=200, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=200, out_features=88, bias=True)\n",
              "        (norm1): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=88, out_features=88, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=88, out_features=200, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=200, out_features=88, bias=True)\n",
              "        (norm1): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zPJFsMO_gWf"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0 # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "import time\n",
        "def train():\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(TEXT.vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        optimizer.zero_grad()\n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    ntokens = len(TEXT.vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6c2_bkM_kQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e616750-4509-4f34-f499-7377051e6f21"
      },
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "epochs = 3 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train()\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20])\n",
            "src torch.Size([35, 20, 200])\n",
            "src torch.Size([35, 20, 200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-69255d737ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-986089ee6fe8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7u9hAnDtvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f701c7ce-0d70-4008-96ad-0a60421f0dc6"
      },
      "source": [
        "data, targets = get_batch(train_data, 0)\n",
        "src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "output = model(data, src_mask)\n",
        "out, out_idx = torch.max(output, 2)\n",
        "#\n",
        "for (pred, tar) in zip(out_idx[0].cpu().numpy().tolist(), data[0].cpu().numpy().tolist()):\n",
        "    print('{}       {}'.format(TEXT.vocab.itos[pred], TEXT.vocab.itos[tar]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<eos>        \n",
            "it       so\n",
            "asteroid       an\n",
            "the       .\n",
            "unk       <\n",
            "successful       increasingly\n",
            "was       tech\n",
            "the       and\n",
            "the       .\n",
            "of       form\n",
            ",       gentil\n",
            ",       greene\n",
            ",       book\n",
            "yard       @-@\n",
            ",       star\n",
            "and       ,\n",
            "jackson       walter\n",
            "it       that\n",
            "second       the\n",
            "it       that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLcK94Faz198"
      },
      "source": [
        "# rough"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhVbTPfdo1L7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83634aa8-017f-42d1-b7f9-13ed6f203708"
      },
      "source": [
        "x = torch.randn(2,2,2)\n",
        "print(x)\n",
        "y = 1 - x\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3318, -0.0384],\n",
            "         [ 0.6170,  0.4005]],\n",
            "\n",
            "        [[ 0.7947, -0.3588],\n",
            "         [ 0.7678, -0.0138]]])\n",
            "tensor([[[1.3318, 1.0384],\n",
            "         [0.3830, 0.5995]],\n",
            "\n",
            "        [[0.2053, 1.3588],\n",
            "         [0.2322, 1.0138]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr7VNlArz34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc13a3cf-7cf9-4540-e35e-9857de86314a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "m = nn.Linear(50, 30)\n",
        "input = torch.randn(128, 30,50)\n",
        "output = m(input)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 30, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}