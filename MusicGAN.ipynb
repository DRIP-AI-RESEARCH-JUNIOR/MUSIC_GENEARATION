{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvnhekQrFuzhwpoM+sP2wN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRIP-AI-RESEARCH-JUNIOR/MUSIC_GENEARATION/blob/master/MusicGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davTem7PZuOm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6XMbENLZ_Q3"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,num_features,p=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc_encoder = nn.Linear(2*num_features,num_features)\n",
        "        self.lstmCell_encoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.fc_decoder = nn.Linear(num_features,num_features)\n",
        "        self.lstmCell_decoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "\n",
        "    def weight_init(self):\n",
        "        torch.nn.init.zeros_(tensor)\n",
        "\n",
        "    def forward(self,x,he,ce,hd,cd):\n",
        "        output = []\n",
        "        seq_len = x.size()[1]\n",
        "        batch = x.size()[0]\n",
        "        num_features = x.size()[2]\n",
        "        input = x.permute(1,0,2)\n",
        "        start = nn.init.uniform_(torch.empty(batch,num_features))\n",
        "        for x_step in input:\n",
        "            input_concat = torch.cat((x_step,start),dim=-1)\n",
        "            linear_out_encoder = F.relu(self.fc_encoder(input_concat))\n",
        "            he,ce = self.lstmCell_encoder(linear_out_encoder,(he,ce))\n",
        "            he = self.dropout(he)\n",
        "            hd,cd = self.lstmCell_decoder(he,(hd,cd))\n",
        "            start = F.sigmoid(self.fc_decoder(hd))\n",
        "            output.append(start)\n",
        "        output = torch.stack(output)\n",
        "        output = output.permute(1,0,2)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cUqtYhhPa1"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "he = torch.randn(2,88)\n",
        "ce = torch.randn(2,88)\n",
        "hd = torch.randn(2,88)\n",
        "cd = torch.randn(2,88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc2zKjh_hobb",
        "outputId": "0a7691aa-c880-48c9-d862-995c3adf146f"
      },
      "source": [
        "model = Generator(88)\n",
        "out = model(x,he,ce,hd,cd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a4DJko9ik_U",
        "outputId": "dae44406-d532-49e2-f87f-cc4e2cf84ebe"
      },
      "source": [
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS5IfxmBt0ea"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,num_feature,p=0.1):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.lstm = nn.LSTM(num_feature,int(num_feature/2),num_layers=2,batch_first=True,bidirectional=True)\n",
        "        self.fc = nn.Linear(num_feature,1)\n",
        "\n",
        "    def forward(self,x,h,c):\n",
        "        drop_D = self.dropout(x)\n",
        "        out,(h,c) = self.lstm(x,(h,c))\n",
        "        out = F.sigmoid(self.fc(out))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luZ9iYDMvdGQ",
        "outputId": "d3445bdd-cf7a-4b1e-a20c-27047c346da0"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "h = torch.randn(4,2,44)\n",
        "c = torch.randn(4,2,44)\n",
        "model = Discriminator(88)\n",
        "out = model(x,h,c)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ftgJ7CULUt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_mPBSeVUMQr"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Nottingham /content\n",
        "!cp -r /content/drive/My\\ Drive/midi /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOcff-gTURL3"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "sys.path.append('midi')\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtaF-CKxUX7u"
      },
      "source": [
        "from midi_utils import midiread, midiwrite\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "from IPython.display import FileLink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlaFpkFVUY32"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        " \n",
        " \n",
        "def midi_filename_to_piano_roll(midi_filename):\n",
        "    \n",
        "    midi_data = midiread(midi_filename, dt=0.3)\n",
        "    \n",
        "    piano_roll = midi_data.piano_roll.transpose()\n",
        "    \n",
        "    # Pressed notes are replaced by 1\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    return piano_roll\n",
        " \n",
        " \n",
        "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
        "        \n",
        "    original_piano_roll_length = piano_roll.shape[1]\n",
        "    \n",
        "    padded_piano_roll = np.zeros((88, max_length))\n",
        "    padded_piano_roll[:] = pad_value\n",
        "    \n",
        "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
        " \n",
        "    return padded_piano_roll\n",
        " \n",
        " \n",
        "class NotesGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
        "        \n",
        "        self.midi_folder_path = midi_folder_path\n",
        "        \n",
        "        midi_filenames = os.listdir(midi_folder_path)\n",
        "        \n",
        "        self.longest_sequence_length = longest_sequence_length\n",
        "        \n",
        "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
        "        \n",
        "        self.midi_full_filenames = list(midi_full_filenames)\n",
        "        \n",
        "        if longest_sequence_length is None:\n",
        "            \n",
        "            self.update_the_max_length()\n",
        "    \n",
        "    \n",
        "    def update_the_max_length(self):\n",
        "        \n",
        "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
        "        \n",
        "        max_length = max(sequences_lengths)\n",
        "        \n",
        "        self.longest_sequence_length = max_length\n",
        "                \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.midi_full_filenames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        midi_full_filename = self.midi_full_filenames[index]\n",
        "        \n",
        "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
        "        # print(\"piano_roll\",piano_roll.shape)\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        sequence_length = piano_roll.shape[1] - 1\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        input_sequence = piano_roll[:, :-1]\n",
        "        # print(\"input_sequence\",input_sequence.shape)\n",
        "        ground_truth_sequence = piano_roll[:, 1:]\n",
        "        # print(\"ground_truth\",ground_truth_sequence.shape)\n",
        "                \n",
        "        # padding sequence so that all of them have the same length\n",
        "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
        "        # print(\"input_sequence_padded\",input_sequence_padded.shape)\n",
        "        \n",
        "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
        "        # print(\"ground_sequence_padded\",ground_truth_sequence_padded.shape)\n",
        "                \n",
        "        input_sequence_padded = input_sequence_padded.transpose()\n",
        "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
        "        \n",
        "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
        " \n",
        "    \n",
        "def post_process_sequence_batch(batch_tuple):\n",
        "    \n",
        "    input_sequences, output_sequences, lengths = batch_tuple\n",
        "    \n",
        "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "    splitted_lengths_batch = lengths.split(split_size=1)\n",
        " \n",
        "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                               splitted_output_sequence_batch,\n",
        "                               splitted_lengths_batch)\n",
        " \n",
        "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                         key=lambda p: int(p[2]),\n",
        "                                         reverse=True)\n",
        " \n",
        "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        " \n",
        "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "    \n",
        "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    \n",
        "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "    \n",
        "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
        "    \n",
        "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAzF9vXjUbNl"
      },
      "source": [
        "trainset = NotesGenerationDataset('Nottingham/train/', longest_sequence_length=None)\n",
        " \n",
        "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myQ5L3fDUeYt"
      },
      "source": [
        "valset = NotesGenerationDataset('Nottingham/valid/', longest_sequence_length=None)\n",
        " \n",
        "valset_loader = data.DataLoader(valset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBCtM6KpTZ00"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hiddeen_dim\n",
        "        self.device = device\n",
        "        self.num_fea = num_fea\n",
        "\n",
        "        self.en_fc = nn.Linear(2*num_fea, hidden_dim)\n",
        "        self.en_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.bottleneck_drop = nn.Dropout(p=drop)\n",
        "\n",
        "        self.de_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "        self.de_fc = nn.Linear(hidden_dim, num_fea)\n",
        "\n",
        "    def forward(self, x, states):\n",
        "        batch_size, seq_len, num_fea = x\n",
        "\n",
        "        # seq_len*(batch_size*num_fea)\n",
        "        x = torch.split(x, 1, dim=1)\n",
        "        x = [x_.squeeze(dim=1) for x_ in x]\n",
        "\n",
        "        sos = torch.empty([batch_size, num_fea]).uniform_().to(self.device)\n",
        "\n",
        "        en_state, de_state = states\n",
        "        out_fea = []\n",
        "\n",
        "        for x_ in x:\n",
        "            input = torch.cat((z_, sos), dim=-1)\n",
        "            en_out = F.relu(self.en_fc(input))\n",
        "            hE, cE = self.en_lstm(en_out, en_state)\n",
        "            \n",
        "            hE = self.bottleneck_drop(hE)\n",
        "\n",
        "            hD, cD = self.de_lstm(hE, de_state)\n",
        "            sos = self.de_fc(hD)\n",
        "\n",
        "            out_fea.append(sos)\n",
        "\n",
        "            en_state = (hE, cE)\n",
        "            de_state = (hD, cD)\n",
        "\n",
        "        out_fea = torch.stack(out_fea, dim=1) # s,b,n -> b,s,n\n",
        "        states = (en_state, de_state)\n",
        "        return out_fea, states\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = ((w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)),\n",
        "             (w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)))\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsP0yFuaTfAS"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.num_layers = 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.drop = nn.Dropout(p=drop)\n",
        "        self.lstm = nn.LSTM(input_size=num_fea, hidden_size=hidden_dim, num_layers=self.num_layers,\n",
        "                            batch_first=True, dropout=drop, bidirectional=True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        lstm_out, state = self.lstm(self.drop(x), state) # b, s, 2*h\n",
        "        out = torch.sigmoid(self.fc(lstm_out)) # b, s, 1\n",
        "\n",
        "        out = torch.mean(out, dim=tuple(range(1, len(out.shape))))\n",
        "\n",
        "        return out, lstm_out, state\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = (w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "             w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device))\n",
        "        \n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2mY16xTiE6"
      },
      "source": [
        "EPS = 1e-40\n",
        "class GenLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GenLoss, self).__init__()\n",
        "\n",
        "    def forward(seld, fake_logits):\n",
        "        return torch.mean(-torch.log(torch.clamp(fake_logits, EPS, 1.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oartZTXTlEt"
      },
      "source": [
        "class DisLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, smooth=False):\n",
        "        super(DisLoss, self).__init__()\n",
        "\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, real_logits, fake_logits):\n",
        "\n",
        "        # loss = -(ylog(p) + (1-y)log(1-p))\n",
        "\n",
        "        d_loss_real = -torch.log(torch.clamp(real_logits, EPS, 1.0))\n",
        "\n",
        "        if self.smooth:\n",
        "            d_loss_fake = torch.log(torch.clamp((1-real_logits), EPS, 1.0))\n",
        "            d_loss_real = 0.9*d_loss_real + 0.1*d_loss_fake\n",
        "        \n",
        "        d_loss_fake = torch.log(torch.clamp((1-fake_logits), EPS, 1.0))\n",
        "\n",
        "        return torch.mean(d_loss_real + d_loss_fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P_DOFIQToFE"
      },
      "source": [
        "def train(train_loader, net_g, net_d, optimizer_g, optimizer_d):\n",
        "\n",
        "    net_g.train()\n",
        "    net_d.train()\n",
        "\n",
        "    d_total_loss = 0\n",
        "    g_total_loss = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        state_g = net_g.init_hidden(batch.shape[0])\n",
        "        state_d = net_d.init_hidden(batch.shape[0])\n",
        "\n",
        "        # Net-G\n",
        "        optimizer_g.zero_grad()\n",
        "        x = torch.empty([batch.shape[0], MAX_SEQ, num_fea]).uniform_()\n",
        "        \n",
        "        g_fea, _ = net_g(x, state_g)\n",
        "        d_logit_fake,_ = net_d(g_fea, state_d)\n",
        "        loss_g = GenLoss()(d_logit_fake)\n",
        "\n",
        "        loss_g.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Net-D\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        d_logits_real,_,_ = net_d(batch.to(device), state_d)\n",
        "\n",
        "        d_logits_fake,_,_ = net_d(g_fea.detach(), state_d)\n",
        "\n",
        "        loss_d = DisLoss(l_s)(d_logits_real, d_logits_fake)\n",
        "\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        g_total_loss += loss_g.item()\n",
        "        d_total_loss += loss_d.item()\n",
        "        n_correct += (d_logits_real>0.5).sum().item() + (d_logits_fake<0.5).sum().item()\n",
        "\n",
        "    return all model and losses and accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvF-RumdTqp5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}