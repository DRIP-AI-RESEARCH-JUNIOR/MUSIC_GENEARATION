{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGAN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMoInd0884I1k2hA9frQ7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRIP-AI-RESEARCH-JUNIOR/MUSIC_GENEARATION/blob/master/MusicGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davTem7PZuOm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnq6SQQX0QFH"
      },
      "source": [
        "# testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6XMbENLZ_Q3"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,num_features,p=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc_encoder = nn.Linear(2*num_features,num_features)\n",
        "        self.lstmCell_encoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.fc_decoder = nn.Linear(num_features,num_features)\n",
        "        self.lstmCell_decoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "\n",
        "    def weight_init(self):\n",
        "        torch.nn.init.zeros_(tensor)\n",
        "\n",
        "    def forward(self,x,he,ce,hd,cd):\n",
        "        output = []\n",
        "        seq_len = x.size()[1]\n",
        "        batch = x.size()[0]\n",
        "        num_features = x.size()[2]\n",
        "        input = x.permute(1,0,2)\n",
        "        start = nn.init.uniform_(torch.empty(batch,num_features))\n",
        "        for x_step in input:\n",
        "            input_concat = torch.cat((x_step,start),dim=-1)\n",
        "            linear_out_encoder = F.relu(self.fc_encoder(input_concat))\n",
        "            he,ce = self.lstmCell_encoder(linear_out_encoder,(he,ce))\n",
        "            he = self.dropout(he)\n",
        "            hd,cd = self.lstmCell_decoder(he,(hd,cd))\n",
        "            start = F.sigmoid(self.fc_decoder(hd))\n",
        "            output.append(start)\n",
        "        output = torch.stack(output)\n",
        "        output = output.permute(1,0,2)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cUqtYhhPa1"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "he = torch.randn(2,88)\n",
        "ce = torch.randn(2,88)\n",
        "hd = torch.randn(2,88)\n",
        "cd = torch.randn(2,88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc2zKjh_hobb",
        "outputId": "0a7691aa-c880-48c9-d862-995c3adf146f"
      },
      "source": [
        "model = Generator(88)\n",
        "out = model(x,he,ce,hd,cd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a4DJko9ik_U",
        "outputId": "dae44406-d532-49e2-f87f-cc4e2cf84ebe"
      },
      "source": [
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS5IfxmBt0ea"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,num_feature,p=0.1):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.lstm = nn.LSTM(num_feature,int(num_feature/2),num_layers=2,batch_first=True,bidirectional=True)\n",
        "        self.fc = nn.Linear(num_feature,1)\n",
        "\n",
        "    def forward(self,x,h,c):\n",
        "        drop_D = self.dropout(x)\n",
        "        out,(h,c) = self.lstm(x,(h,c))\n",
        "        out = F.sigmoid(self.fc(out))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luZ9iYDMvdGQ",
        "outputId": "d3445bdd-cf7a-4b1e-a20c-27047c346da0"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "h = torch.randn(4,2,44)\n",
        "c = torch.randn(4,2,44)\n",
        "model = Discriminator(88)\n",
        "out = model(x,h,c)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COQpbL-D0XS5"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ftgJ7CULUt",
        "outputId": "858b85db-153f-4501-935e-b95210cbc07b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_mPBSeVUMQr"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Nottingham /content\n",
        "!cp -r /content/drive/My\\ Drive/midi /content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOcff-gTURL3"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "sys.path.append('midi')\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtaF-CKxUX7u"
      },
      "source": [
        "from midi_utils import midiread, midiwrite\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "from IPython.display import FileLink"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlaFpkFVUY32"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        " \n",
        " \n",
        "def midi_filename_to_piano_roll(midi_filename):\n",
        "    \n",
        "    midi_data = midiread(midi_filename, dt=0.3)\n",
        "    \n",
        "    piano_roll = midi_data.piano_roll.transpose()\n",
        "    \n",
        "    # Pressed notes are replaced by 1\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    return piano_roll\n",
        " \n",
        " \n",
        "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
        "        \n",
        "    original_piano_roll_length = piano_roll.shape[1]\n",
        "    \n",
        "    padded_piano_roll = np.zeros((88, max_length))\n",
        "    padded_piano_roll[:] = pad_value\n",
        "    \n",
        "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
        " \n",
        "    return padded_piano_roll\n",
        " \n",
        " \n",
        "class NotesGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
        "        \n",
        "        self.midi_folder_path = midi_folder_path\n",
        "        \n",
        "        midi_filenames = os.listdir(midi_folder_path)\n",
        "        \n",
        "        self.longest_sequence_length = longest_sequence_length\n",
        "        \n",
        "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
        "        \n",
        "        self.midi_full_filenames = list(midi_full_filenames)\n",
        "        \n",
        "        if longest_sequence_length is None:\n",
        "            \n",
        "            self.update_the_max_length()\n",
        "    \n",
        "    \n",
        "    def update_the_max_length(self):\n",
        "        \n",
        "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
        "        \n",
        "        max_length = max(sequences_lengths)\n",
        "        \n",
        "        self.longest_sequence_length = max_length\n",
        "                \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.midi_full_filenames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        midi_full_filename = self.midi_full_filenames[index]\n",
        "        \n",
        "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
        "        # print(\"piano_roll\",piano_roll.shape)\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        sequence_length = piano_roll.shape[1] \n",
        "        \n",
        "        # Shifting by one time step\n",
        "        # input_sequence = piano_roll[:, :-1]\n",
        "        # print(\"input_sequence\",input_sequence.shape)\n",
        "        # ground_truth_sequence = piano_roll[:, 1:]\n",
        "        # print(\"ground_truth\",ground_truth_sequence.shape)\n",
        "                \n",
        "        # padding sequence so that all of them have the same length\n",
        "        input_sequence_padded = pad_piano_roll(piano_roll, max_length=self.longest_sequence_length)\n",
        "        # print(\"input_sequence_padded\",input_sequence_padded.shape)\n",
        "        \n",
        "        ground_truth_sequence_padded = pad_piano_roll(piano_roll,max_length=self.longest_sequence_length,pad_value=-100)\n",
        "        # print(\"ground_sequence_padded\",ground_truth_sequence_padded.shape)\n",
        "                \n",
        "        input_sequence_padded = input_sequence_padded.transpose()\n",
        "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
        "        \n",
        "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
        " \n",
        "    \n",
        "def post_process_sequence_batch(batch_tuple):\n",
        "    \n",
        "    input_sequences, output_sequences, lengths = batch_tuple\n",
        "    \n",
        "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "    splitted_lengths_batch = lengths.split(split_size=1)\n",
        " \n",
        "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                               splitted_output_sequence_batch,\n",
        "                               splitted_lengths_batch)\n",
        " \n",
        "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                         key=lambda p: int(p[2]),\n",
        "                                         reverse=True)\n",
        " \n",
        "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        " \n",
        "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "    \n",
        "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    \n",
        "    # input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "    \n",
        "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
        "    \n",
        "    return input_sequence_batch_sorted, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAzF9vXjUbNl"
      },
      "source": [
        "trainset = NotesGenerationDataset('Nottingham/train/', longest_sequence_length=None)\n",
        " \n",
        "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myQ5L3fDUeYt"
      },
      "source": [
        "valset = NotesGenerationDataset('Nottingham/valid/', longest_sequence_length=None)\n",
        " \n",
        "valset_loader = data.DataLoader(valset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XYmVTxRXGWL",
        "outputId": "30fbabf6-0f5e-4c89-b652-9a07a6ce19da"
      },
      "source": [
        "batch = next(iter(trainset_loader))\n",
        "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1)\n",
        " \n",
        "# input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var = input_sequences_batch\n",
        "input_sequences_batch_var.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 481, 88])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBCtM6KpTZ00"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        self.num_fea = num_fea\n",
        "\n",
        "        self.en_fc = nn.Linear(2*num_fea, hidden_dim)\n",
        "        self.en_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.bottleneck_drop = nn.Dropout(p=drop)\n",
        "\n",
        "        self.de_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "        self.de_fc = nn.Linear(hidden_dim, num_fea)\n",
        "\n",
        "    def forward(self, x, states):\n",
        "        batch_size, seq_len, num_fea = x.size()[0],x.size()[1],x.size()[2]\n",
        "\n",
        "        # seq_len*(batch_size*num_fea)\n",
        "        x = torch.split(x, 1, dim=1)\n",
        "        x = [x_.squeeze(dim=1) for x_ in x]\n",
        "\n",
        "        sos = torch.empty([batch_size, num_fea]).uniform_().to(self.device)\n",
        "\n",
        "        en_state, de_state = states\n",
        "        out_fea = []\n",
        "\n",
        "        for x_ in x:\n",
        "            input = torch.cat((x_, sos), dim=-1)\n",
        "            en_out = F.relu(self.en_fc(input))\n",
        "            hE, cE = self.en_lstm(en_out, en_state)\n",
        "            \n",
        "            hE = self.bottleneck_drop(hE)\n",
        "\n",
        "            hD, cD = self.de_lstm(hE, de_state)\n",
        "            sos = self.de_fc(hD)\n",
        "\n",
        "            out_fea.append(sos)\n",
        "\n",
        "            en_state = (hE, cE)\n",
        "            de_state = (hD, cD)\n",
        "\n",
        "        out_fea = torch.stack(out_fea, dim=1) # s,b,n -> b,s,n\n",
        "        states = (en_state, de_state)\n",
        "        return out_fea, states\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = ((w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)),\n",
        "             (w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)))\n",
        "        return h"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsP0yFuaTfAS"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.num_layers = 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.drop = nn.Dropout(p=drop)\n",
        "        self.lstm = nn.LSTM(input_size=num_fea, hidden_size=hidden_dim, num_layers=self.num_layers,\n",
        "                            batch_first=True, dropout=drop, bidirectional=True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        lstm_out, state = self.lstm(self.drop(x), state) # b, s, 2*h\n",
        "        out = torch.sigmoid(self.fc(lstm_out)) # b, s, 1\n",
        "\n",
        "        out = torch.mean(out, dim=tuple(range(1, len(out.shape))))\n",
        "\n",
        "        return out, lstm_out, state\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = (w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "             w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device))\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2mY16xTiE6"
      },
      "source": [
        "EPS = 1e-40\n",
        "class GenLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GenLoss, self).__init__()\n",
        "\n",
        "    def forward(seld, fake_logits):\n",
        "        return torch.mean(-torch.log(torch.clamp(fake_logits, EPS, 1.0)))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oartZTXTlEt"
      },
      "source": [
        "class DisLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, smooth=False):\n",
        "        super(DisLoss, self).__init__()\n",
        "\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, real_logits, fake_logits):\n",
        "\n",
        "        # loss = -(ylog(p) + (1-y)log(1-p))\n",
        "\n",
        "        d_loss_real = -torch.log(torch.clamp(real_logits, EPS, 1.0))\n",
        "\n",
        "        if self.smooth:\n",
        "            d_loss_fake = torch.log(torch.clamp((1-real_logits), EPS, 1.0))\n",
        "            d_loss_real = 0.9*d_loss_real + 0.1*d_loss_fake\n",
        "        \n",
        "        d_loss_fake = -torch.log(torch.clamp((1-fake_logits), EPS, 1.0))\n",
        "\n",
        "        return torch.mean(d_loss_real + d_loss_fake)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADIRcJHYZN4Q",
        "outputId": "e53ebcb2-97c3-4261-f32c-f0010d23a03b"
      },
      "source": [
        "state_g = model_G.init_hidden(input_sequences_batch_var.shape[0])\n",
        "out,_ = model_G(input_sequences_batch_var,state_g)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 481, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaEk80A4Yu2H"
      },
      "source": [
        "device = 'cuda'\n",
        "N_epoch = 100\n",
        "net_g = Generator(num_fea=88,device=device).to(device)\n",
        "net_d = Discriminator(num_fea=88,device=device).to(device)\n",
        "criterion_g =  GenLoss()\n",
        "criterion_d = DisLoss(smooth=True)\n",
        "optimizer_g = optim.SGD(net_g.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_d = optim.SGD(net_d.parameters(), lr=0.005, momentum=0.9)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P_DOFIQToFE"
      },
      "source": [
        "def train(trainset_loader, net_g, net_d, optimizer_g, optimizer_d,freeze_d=False,freeze_g=False):\n",
        "\n",
        "    net_g.train()\n",
        "    net_d.train()\n",
        "\n",
        "    d_total_loss = 0\n",
        "    g_total_loss = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    for i, batch in enumerate(trainset_loader):\n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "        input_sequences_batch = input_sequences_batch.to(device)\n",
        "        state_g = net_g.init_hidden(input_sequences_batch.shape[0])\n",
        "        state_d = net_d.init_hidden(input_sequences_batch.shape[0])\n",
        "        MAX_SEQ = input_sequences_batch.shape[1]\n",
        "        num_fea = input_sequences_batch.shape[2]\n",
        "\n",
        "        # Net-G\n",
        "        if not freeze_g:\n",
        "\n",
        "            optimizer_g.zero_grad()\n",
        "        x = torch.empty([input_sequences_batch.shape[0], MAX_SEQ, num_fea]).uniform_().to(device)\n",
        "        \n",
        "        g_fea, _ = net_g(x, state_g)\n",
        "        # print(\"d_fea\",g_fea)\n",
        "        d_logit_fake,_,_ = net_d(g_fea, state_d)\n",
        "        # print(\"d_logit\",d_logit_fake)\n",
        "        loss_g = criterion_g(d_logit_fake)\n",
        "        # print(\"loss_g\",loss_g)\n",
        "        if not freeze_g:\n",
        "            loss_g.backward()\n",
        "            nn.utils.clip_grad_norm_(net_g.parameters(),max_norm=5.0)\n",
        "            optimizer_g.step()\n",
        "\n",
        "        # Net-D\n",
        "        if not freeze_d:\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "        d_logits_real,_,_ = net_d(input_sequences_batch, state_d)\n",
        "        # print(\"d_logits_real\", d_logits_real)\n",
        "\n",
        "        d_logits_fake,_,_ = net_d(g_fea.detach(), state_d)\n",
        "\n",
        "        loss_d = criterion_d(d_logits_real, d_logits_fake)\n",
        "        if not freeze_d:\n",
        "            loss_d.backward()\n",
        "            nn.utils.clip_grad_norm_(net_d.parameters(),max_norm=5.0)\n",
        "            optimizer_d.step()\n",
        "\n",
        "        g_total_loss += loss_g.item()\n",
        "        d_total_loss += loss_d.item()\n",
        "        n_correct += (d_logits_real>0.5).sum().item() + (d_logits_fake<0.5).sum().item()\n",
        "\n",
        "    return net_g,net_d,optimizer_g,optimizer_d,g_total_loss/len(trainset_loader),d_total_loss/len(trainset_loader),n_correct/len(trainset_loader)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArJNCYhliiLs",
        "outputId": "c96b66da-d7ef-4309-a834-685643c084a0"
      },
      "source": [
        "net_g,net_d,c,d,e = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d)\n",
        "print(c,d,e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6916093819363173 1.2369987950768582 11.36046511627907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxtF0TWWuIWj"
      },
      "source": [
        "def main(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,N_epoch):\n",
        "    accuracy = 0\n",
        "    for epoch in range(N_epoch):\n",
        "        if accuracy > 90:\n",
        "            net_g,net_d,optimzer_g,optimizer_d,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,True,True)\n",
        "            print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))\n",
        "        else:\n",
        "            net_g,net_d,optimzer_g,optimizer_d,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d)\n",
        "            print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))\n",
        "\n",
        "        "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG9CQWkTKRxS",
        "outputId": "c886a05a-57e5-4761-a97f-fe17ae178b9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(10):\n",
        "    net_g,net_d,_,_,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,False,True)\n",
        "    print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))\n",
        "\n",
        "for epoch in range(10):\n",
        "    net_g,net_d,_,_,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,True,False)\n",
        "    print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 generator_loss:4.714 discriminator_loss:-0.274 accuracy:14.802\n",
            "Epoch:1 generator_loss:7.132 discriminator_loss:-5.593 accuracy:16.000\n",
            "Epoch:2 generator_loss:9.156 discriminator_loss:-7.981 accuracy:16.000\n",
            "Epoch:3 generator_loss:10.099 discriminator_loss:-7.542 accuracy:16.000\n",
            "Epoch:4 generator_loss:10.511 discriminator_loss:-8.069 accuracy:16.000\n",
            "Epoch:5 generator_loss:10.917 discriminator_loss:-7.981 accuracy:16.000\n",
            "Epoch:6 generator_loss:11.284 discriminator_loss:-7.543 accuracy:16.000\n",
            "Epoch:7 generator_loss:11.352 discriminator_loss:-7.806 accuracy:16.000\n",
            "Epoch:8 generator_loss:11.727 discriminator_loss:-7.543 accuracy:16.000\n",
            "Epoch:9 generator_loss:11.848 discriminator_loss:-7.982 accuracy:16.000\n",
            "Epoch:0 generator_loss:0.226 discriminator_loss:47.404 accuracy:8.512\n",
            "Epoch:1 generator_loss:0.000 discriminator_loss:65.823 accuracy:8.000\n",
            "Epoch:2 generator_loss:0.000 discriminator_loss:65.157 accuracy:8.000\n",
            "Epoch:3 generator_loss:0.000 discriminator_loss:64.249 accuracy:8.000\n",
            "Epoch:4 generator_loss:0.000 discriminator_loss:66.180 accuracy:8.000\n",
            "Epoch:5 generator_loss:0.000 discriminator_loss:65.947 accuracy:8.000\n",
            "Epoch:6 generator_loss:0.000 discriminator_loss:69.376 accuracy:8.000\n",
            "Epoch:7 generator_loss:0.000 discriminator_loss:65.065 accuracy:8.000\n",
            "Epoch:8 generator_loss:0.000 discriminator_loss:65.702 accuracy:8.000\n",
            "Epoch:9 generator_loss:0.000 discriminator_loss:66.403 accuracy:8.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "do8j5VURxCAs",
        "outputId": "8ed9678d-301e-49a6-ce5a-e2c7643f2fd5"
      },
      "source": [
        "main(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,N_epoch)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 generator_loss:0.704 discriminator_loss:1.234 accuracy:12.570\n",
            "Epoch:1 generator_loss:0.682 discriminator_loss:1.250 accuracy:7.023\n",
            "Epoch:2 generator_loss:0.714 discriminator_loss:1.250 accuracy:6.058\n",
            "Epoch:3 generator_loss:0.691 discriminator_loss:1.249 accuracy:7.895\n",
            "Epoch:4 generator_loss:0.704 discriminator_loss:1.217 accuracy:11.674\n",
            "Epoch:5 generator_loss:0.701 discriminator_loss:1.278 accuracy:5.791\n",
            "Epoch:6 generator_loss:0.548 discriminator_loss:1.521 accuracy:6.140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0389bbb56f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-c8858a71a735>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(trainset_loader, net_g, net_d, optimizer_g, optimizer_d, N_epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimzer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-00c54630a53a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainset_loader, net_g, net_d, optimizer_g, optimizer_d, freeze_d, freeze_g)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_logits_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_logits_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfreeze_d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}