{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5zUDP8n2ptuOln/NzbX0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DRIP-AI-RESEARCH-JUNIOR/MUSIC_GENEARATION/blob/master/MusicGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davTem7PZuOm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnq6SQQX0QFH"
      },
      "source": [
        "# testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6XMbENLZ_Q3"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,num_features,p=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc_encoder = nn.Linear(2*num_features,num_features)\n",
        "        self.lstmCell_encoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.fc_decoder = nn.Linear(num_features,num_features)\n",
        "        self.lstmCell_decoder = nn.LSTMCell(input_size=num_features, hidden_size=num_features)\n",
        "\n",
        "    def weight_init(self):\n",
        "        torch.nn.init.zeros_(tensor)\n",
        "\n",
        "    def forward(self,x,he,ce,hd,cd):\n",
        "        output = []\n",
        "        seq_len = x.size()[1]\n",
        "        batch = x.size()[0]\n",
        "        num_features = x.size()[2]\n",
        "        input = x.permute(1,0,2)\n",
        "        start = nn.init.uniform_(torch.empty(batch,num_features))\n",
        "        for x_step in input:\n",
        "            input_concat = torch.cat((x_step,start),dim=-1)\n",
        "            linear_out_encoder = F.relu(self.fc_encoder(input_concat))\n",
        "            he,ce = self.lstmCell_encoder(linear_out_encoder,(he,ce))\n",
        "            he = self.dropout(he)\n",
        "            hd,cd = self.lstmCell_decoder(he,(hd,cd))\n",
        "            start = F.sigmoid(self.fc_decoder(hd))\n",
        "            output.append(start)\n",
        "        output = torch.stack(output)\n",
        "        output = output.permute(1,0,2)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cUqtYhhPa1"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "he = torch.randn(2,88)\n",
        "ce = torch.randn(2,88)\n",
        "hd = torch.randn(2,88)\n",
        "cd = torch.randn(2,88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc2zKjh_hobb",
        "outputId": "0a7691aa-c880-48c9-d862-995c3adf146f"
      },
      "source": [
        "model = Generator(88)\n",
        "out = model(x,he,ce,hd,cd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a4DJko9ik_U",
        "outputId": "dae44406-d532-49e2-f87f-cc4e2cf84ebe"
      },
      "source": [
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS5IfxmBt0ea"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,num_feature,p=0.1):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.lstm = nn.LSTM(num_feature,int(num_feature/2),num_layers=2,batch_first=True,bidirectional=True)\n",
        "        self.fc = nn.Linear(num_feature,1)\n",
        "\n",
        "    def forward(self,x,h,c):\n",
        "        drop_D = self.dropout(x)\n",
        "        out,(h,c) = self.lstm(x,(h,c))\n",
        "        out = F.sigmoid(self.fc(out))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luZ9iYDMvdGQ",
        "outputId": "d3445bdd-cf7a-4b1e-a20c-27047c346da0"
      },
      "source": [
        "x = torch.randn(2,3,88)\n",
        "h = torch.randn(4,2,44)\n",
        "c = torch.randn(4,2,44)\n",
        "model = Discriminator(88)\n",
        "out = model(x,h,c)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COQpbL-D0XS5"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ftgJ7CULUt",
        "outputId": "f5eafebc-f9a5-40d7-adc6-dbfad597303e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_mPBSeVUMQr"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Nottingham /content\n",
        "!cp -r /content/drive/My\\ Drive/midi /content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOcff-gTURL3"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "sys.path.append('midi')\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtaF-CKxUX7u"
      },
      "source": [
        "from midi_utils import midiread, midiwrite\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "from IPython.display import FileLink"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlaFpkFVUY32"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        " \n",
        " \n",
        "def midi_filename_to_piano_roll(midi_filename):\n",
        "    \n",
        "    midi_data = midiread(midi_filename, dt=0.3)\n",
        "    \n",
        "    piano_roll = midi_data.piano_roll.transpose()\n",
        "    \n",
        "    # Pressed notes are replaced by 1\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    return piano_roll\n",
        " \n",
        " \n",
        "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
        "        \n",
        "    original_piano_roll_length = piano_roll.shape[1]\n",
        "    \n",
        "    padded_piano_roll = np.zeros((88, max_length))\n",
        "    padded_piano_roll[:] = pad_value\n",
        "    \n",
        "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
        " \n",
        "    return padded_piano_roll\n",
        " \n",
        " \n",
        "class NotesGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
        "        \n",
        "        self.midi_folder_path = midi_folder_path\n",
        "        \n",
        "        midi_filenames = os.listdir(midi_folder_path)\n",
        "        \n",
        "        self.longest_sequence_length = longest_sequence_length\n",
        "        \n",
        "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
        "        \n",
        "        self.midi_full_filenames = list(midi_full_filenames)\n",
        "        \n",
        "        if longest_sequence_length is None:\n",
        "            \n",
        "            self.update_the_max_length()\n",
        "    \n",
        "    \n",
        "    def update_the_max_length(self):\n",
        "        \n",
        "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
        "        \n",
        "        max_length = max(sequences_lengths)\n",
        "        \n",
        "        self.longest_sequence_length = max_length\n",
        "                \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.midi_full_filenames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        midi_full_filename = self.midi_full_filenames[index]\n",
        "        \n",
        "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
        "        # print(\"piano_roll\",piano_roll.shape)\n",
        "        \n",
        "        # Shifting by one time step\n",
        "        sequence_length = piano_roll.shape[1] \n",
        "        \n",
        "        # Shifting by one time step\n",
        "        # input_sequence = piano_roll[:, :-1]\n",
        "        # print(\"input_sequence\",input_sequence.shape)\n",
        "        # ground_truth_sequence = piano_roll[:, 1:]\n",
        "        # print(\"ground_truth\",ground_truth_sequence.shape)\n",
        "                \n",
        "        # padding sequence so that all of them have the same length\n",
        "        input_sequence_padded = pad_piano_roll(piano_roll, max_length=self.longest_sequence_length)\n",
        "        # print(\"input_sequence_padded\",input_sequence_padded.shape)\n",
        "        \n",
        "        ground_truth_sequence_padded = pad_piano_roll(piano_roll,max_length=self.longest_sequence_length,pad_value=-100)\n",
        "        # print(\"ground_sequence_padded\",ground_truth_sequence_padded.shape)\n",
        "                \n",
        "        input_sequence_padded = input_sequence_padded.transpose()\n",
        "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
        "        \n",
        "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
        " \n",
        "    \n",
        "def post_process_sequence_batch(batch_tuple):\n",
        "    \n",
        "    input_sequences, output_sequences, lengths = batch_tuple\n",
        "    \n",
        "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "    splitted_lengths_batch = lengths.split(split_size=1)\n",
        " \n",
        "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                               splitted_output_sequence_batch,\n",
        "                               splitted_lengths_batch)\n",
        " \n",
        "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                         key=lambda p: int(p[2]),\n",
        "                                         reverse=True)\n",
        " \n",
        "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        " \n",
        "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "    \n",
        "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
        "    \n",
        "    # input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "    \n",
        "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
        "    \n",
        "    return input_sequence_batch_sorted, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAzF9vXjUbNl"
      },
      "source": [
        "trainset = NotesGenerationDataset('Nottingham/train/', longest_sequence_length=None)\n",
        " \n",
        "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myQ5L3fDUeYt"
      },
      "source": [
        "valset = NotesGenerationDataset('Nottingham/valid/', longest_sequence_length=None)\n",
        " \n",
        "valset_loader = data.DataLoader(valset, batch_size=8,shuffle=True, drop_last=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XYmVTxRXGWL",
        "outputId": "30fbabf6-0f5e-4c89-b652-9a07a6ce19da"
      },
      "source": [
        "batch = next(iter(trainset_loader))\n",
        "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        " \n",
        "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1)\n",
        " \n",
        "# input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "input_sequences_batch_var = input_sequences_batch\n",
        "input_sequences_batch_var.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 481, 88])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBCtM6KpTZ00"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        self.num_fea = num_fea\n",
        "\n",
        "        self.en_fc = nn.Linear(2*num_fea, hidden_dim)\n",
        "        self.en_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.bottleneck_drop = nn.Dropout(p=drop)\n",
        "\n",
        "        self.de_lstm = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim)\n",
        "        self.de_fc = nn.Linear(hidden_dim, num_fea)\n",
        "\n",
        "    def forward(self, x, states):\n",
        "        batch_size, seq_len, num_fea = x.size()[0],x.size()[1],x.size()[2]\n",
        "\n",
        "        # seq_len*(batch_size*num_fea)\n",
        "        x = torch.split(x, 1, dim=1)\n",
        "        x = [x_.squeeze(dim=1) for x_ in x]\n",
        "\n",
        "        sos = torch.empty([batch_size, num_fea]).uniform_().to(self.device)\n",
        "\n",
        "        en_state, de_state = states\n",
        "        out_fea = []\n",
        "\n",
        "        for x_ in x:\n",
        "            input = torch.cat((x_, sos), dim=-1)\n",
        "            en_out = F.relu(self.en_fc(input))\n",
        "            hE, cE = self.en_lstm(en_out, en_state)\n",
        "            \n",
        "            hE = self.bottleneck_drop(hE)\n",
        "\n",
        "            hD, cD = self.de_lstm(hE, de_state)\n",
        "            sos = self.de_fc(hD)\n",
        "\n",
        "            out_fea.append(sos)\n",
        "\n",
        "            en_state = (hE, cE)\n",
        "            de_state = (hD, cD)\n",
        "\n",
        "        out_fea = torch.stack(out_fea, dim=1) # s,b,n -> b,s,n\n",
        "        states = (en_state, de_state)\n",
        "        return out_fea, states\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = ((w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)),\n",
        "             (w.new(batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "              w.new(batch_size, self.hidden_dim).zero_().to(self.device)))\n",
        "        return h"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsP0yFuaTfAS"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, num_fea, hidden_dim=256, drop=0.6, device='cuda'):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.num_layers = 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.drop = nn.Dropout(p=drop)\n",
        "        self.lstm = nn.LSTM(input_size=num_fea, hidden_size=hidden_dim, num_layers=self.num_layers,\n",
        "                            batch_first=True, dropout=drop, bidirectional=True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        lstm_out, state = self.lstm(self.drop(x), state) # b, s, 2*h\n",
        "        out = torch.sigmoid(self.fc(lstm_out)) # b, s, 1\n",
        "\n",
        "        out = torch.mean(out, dim=tuple(range(1, len(out.shape))))\n",
        "\n",
        "        return out, lstm_out, state\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        w = next(self.parameters()).data\n",
        "\n",
        "        h = (w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device),\n",
        "             w.new(self.num_layers*2, batch_size, self.hidden_dim).zero_().to(self.device))\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2mY16xTiE6"
      },
      "source": [
        "EPS = 1e-40\n",
        "class GenLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GenLoss, self).__init__()\n",
        "\n",
        "    def forward(seld, fake_logits):\n",
        "        return torch.mean(-torch.log(torch.clamp(fake_logits, EPS, 1.0)))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oartZTXTlEt"
      },
      "source": [
        "class DisLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, smooth=False):\n",
        "        super(DisLoss, self).__init__()\n",
        "\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, real_logits, fake_logits):\n",
        "\n",
        "        # loss = -(ylog(p) + (1-y)log(1-p))\n",
        "\n",
        "        d_loss_real = -torch.log(torch.clamp(real_logits, EPS, 1.0))\n",
        "\n",
        "        if self.smooth:\n",
        "            d_loss_fake = torch.log(torch.clamp((1-real_logits), EPS, 1.0))\n",
        "            d_loss_real = 0.9*d_loss_real + 0.1*d_loss_fake\n",
        "        \n",
        "        d_loss_fake = -torch.log(torch.clamp((1-fake_logits), EPS, 1.0))\n",
        "\n",
        "        return torch.mean(d_loss_real + d_loss_fake)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADIRcJHYZN4Q",
        "outputId": "e53ebcb2-97c3-4261-f32c-f0010d23a03b"
      },
      "source": [
        "state_g = model_G.init_hidden(input_sequences_batch_var.shape[0])\n",
        "out,_ = model_G(input_sequences_batch_var,state_g)\n",
        "print(out.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 481, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaEk80A4Yu2H"
      },
      "source": [
        "device = 'cuda'\n",
        "N_epoch = 100\n",
        "net_g = Generator(num_fea=88,device=device).to(device)\n",
        "net_d = Discriminator(num_fea=88,device=device).to(device)\n",
        "criterion_g =  GenLoss()\n",
        "criterion_d = DisLoss(smooth=True)\n",
        "optimizer_g = optim.SGD(net_g.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_d = optim.SGD(net_d.parameters(), lr=0.005, momentum=0.9)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P_DOFIQToFE"
      },
      "source": [
        "def train(trainset_loader, net_g, net_d, optimizer_g, optimizer_d,freeze_d=False):\n",
        "\n",
        "    net_g.train()\n",
        "    net_d.train()\n",
        "\n",
        "    d_total_loss = 0\n",
        "    g_total_loss = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    for i, batch in enumerate(trainset_loader):\n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "        input_sequences_batch = input_sequences_batch.to(device)\n",
        "        state_g = net_g.init_hidden(input_sequences_batch.shape[0])\n",
        "        state_d = net_d.init_hidden(input_sequences_batch.shape[0])\n",
        "        MAX_SEQ = input_sequences_batch.shape[1]\n",
        "        num_fea = input_sequences_batch.shape[2]\n",
        "\n",
        "        # Net-G\n",
        "        optimizer_g.zero_grad()\n",
        "        x = torch.empty([input_sequences_batch.shape[0], MAX_SEQ, num_fea]).uniform_().to(device)\n",
        "        \n",
        "        g_fea, _ = net_g(x, state_g)\n",
        "        # print(\"d_fea\",g_fea)\n",
        "        d_logit_fake,_,_ = net_d(g_fea, state_d)\n",
        "        # print(\"d_logit\",d_logit_fake)\n",
        "        loss_g = criterion_g(d_logit_fake)\n",
        "        # print(\"loss_g\",loss_g)\n",
        "\n",
        "        loss_g.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Net-D\n",
        "        if not freeze_d:\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "        d_logits_real,_,_ = net_d(input_sequences_batch, state_d)\n",
        "        # print(\"d_logits_real\", d_logits_real)\n",
        "\n",
        "        d_logits_fake,_,_ = net_d(g_fea.detach(), state_d)\n",
        "\n",
        "        loss_d = criterion_d(d_logits_real, d_logits_fake)\n",
        "        if not freeze_d:\n",
        "            loss_d.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "        g_total_loss += loss_g.item()\n",
        "        d_total_loss += loss_d.item()\n",
        "        n_correct += (d_logits_real>0.5).sum().item() + (d_logits_fake<0.5).sum().item()\n",
        "\n",
        "    return net_g,net_d,optimizer_g,optimizer_d,g_total_loss/len(trainset_loader),d_total_loss/len(trainset_loader),n_correct/len(trainset_loader)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArJNCYhliiLs",
        "outputId": "c96b66da-d7ef-4309-a834-685643c084a0"
      },
      "source": [
        "net_g,net_d,c,d,e = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d)\n",
        "print(c,d,e)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6916093819363173 1.2369987950768582 11.36046511627907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxtF0TWWuIWj"
      },
      "source": [
        "def main(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,N_epoch):\n",
        "    accuracy = 0\n",
        "    for epoch in range(N_epoch):\n",
        "        if accuracy > 90:\n",
        "            net_g,net_d,optimzer_g,optimizer_d,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,True)\n",
        "            print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))\n",
        "        else:\n",
        "            net_g,net_d,optimzer_g,optimizer_d,g_loss,d_loss,accuracy = train(trainset_loader,net_g,net_d,optimizer_g,optimizer_d)\n",
        "            print(\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\".format(epoch,g_loss,d_loss,accuracy))\n",
        "\n",
        "        "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "do8j5VURxCAs",
        "outputId": "0b417bdf-d061-4ad7-ead9-28f09ce266f4"
      },
      "source": [
        "main(trainset_loader,net_g,net_d,optimizer_g,optimizer_d,N_epoch)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 generator_loss:0.707 discriminator_loss:1.239 accuracy:11.953\n",
            "Epoch:1 generator_loss:0.689 discriminator_loss:1.243 accuracy:8.349\n",
            "Epoch:2 generator_loss:0.697 discriminator_loss:1.262 accuracy:4.884\n",
            "Epoch:3 generator_loss:0.715 discriminator_loss:1.230 accuracy:10.395\n",
            "Epoch:4 generator_loss:0.679 discriminator_loss:1.257 accuracy:5.500\n",
            "Epoch:5 generator_loss:0.688 discriminator_loss:1.231 accuracy:7.012\n",
            "Epoch:6 generator_loss:0.713 discriminator_loss:1.251 accuracy:7.198\n",
            "Epoch:7 generator_loss:0.538 discriminator_loss:1.500 accuracy:6.000\n",
            "Epoch:8 generator_loss:0.690 discriminator_loss:1.398 accuracy:8.558\n",
            "Epoch:9 generator_loss:1.064 discriminator_loss:1.177 accuracy:10.372\n",
            "Epoch:10 generator_loss:1.086 discriminator_loss:1.204 accuracy:10.349\n",
            "Epoch:11 generator_loss:0.712 discriminator_loss:1.320 accuracy:7.930\n",
            "Epoch:12 generator_loss:0.662 discriminator_loss:1.434 accuracy:2.895\n",
            "Epoch:13 generator_loss:0.671 discriminator_loss:1.275 accuracy:7.593\n",
            "Epoch:14 generator_loss:0.672 discriminator_loss:1.359 accuracy:2.442\n",
            "Epoch:15 generator_loss:0.690 discriminator_loss:1.286 accuracy:3.337\n",
            "Epoch:16 generator_loss:0.701 discriminator_loss:1.262 accuracy:6.663\n",
            "Epoch:17 generator_loss:0.673 discriminator_loss:1.257 accuracy:6.953\n",
            "Epoch:18 generator_loss:0.679 discriminator_loss:1.291 accuracy:4.733\n",
            "Epoch:19 generator_loss:0.684 discriminator_loss:1.275 accuracy:5.209\n",
            "Epoch:20 generator_loss:0.693 discriminator_loss:1.260 accuracy:5.872\n",
            "Epoch:21 generator_loss:0.714 discriminator_loss:1.247 accuracy:7.860\n",
            "Epoch:22 generator_loss:0.678 discriminator_loss:1.275 accuracy:6.849\n",
            "Epoch:23 generator_loss:0.681 discriminator_loss:1.272 accuracy:4.744\n",
            "Epoch:24 generator_loss:0.704 discriminator_loss:1.246 accuracy:8.988\n",
            "Epoch:25 generator_loss:0.695 discriminator_loss:1.247 accuracy:9.023\n",
            "Epoch:26 generator_loss:0.692 discriminator_loss:1.263 accuracy:6.105\n",
            "Epoch:27 generator_loss:0.734 discriminator_loss:1.215 accuracy:8.326\n",
            "Epoch:28 generator_loss:0.659 discriminator_loss:1.315 accuracy:4.430\n",
            "Epoch:29 generator_loss:0.676 discriminator_loss:1.280 accuracy:4.174\n",
            "Epoch:30 generator_loss:0.715 discriminator_loss:1.269 accuracy:9.116\n",
            "Epoch:31 generator_loss:0.683 discriminator_loss:1.264 accuracy:7.430\n",
            "Epoch:32 generator_loss:0.709 discriminator_loss:1.259 accuracy:7.698\n",
            "Epoch:33 generator_loss:0.693 discriminator_loss:1.243 accuracy:8.674\n",
            "Epoch:34 generator_loss:0.687 discriminator_loss:1.255 accuracy:7.756\n",
            "Epoch:35 generator_loss:0.739 discriminator_loss:1.216 accuracy:9.488\n",
            "Epoch:36 generator_loss:0.757 discriminator_loss:1.215 accuracy:10.407\n",
            "Epoch:37 generator_loss:0.663 discriminator_loss:1.273 accuracy:7.279\n",
            "Epoch:38 generator_loss:0.775 discriminator_loss:1.188 accuracy:10.756\n",
            "Epoch:39 generator_loss:0.681 discriminator_loss:1.391 accuracy:5.814\n",
            "Epoch:40 generator_loss:0.702 discriminator_loss:1.346 accuracy:7.570\n",
            "Epoch:41 generator_loss:0.746 discriminator_loss:1.269 accuracy:8.663\n",
            "Epoch:42 generator_loss:0.734 discriminator_loss:1.335 accuracy:6.209\n",
            "Epoch:43 generator_loss:0.661 discriminator_loss:1.320 accuracy:3.267\n",
            "Epoch:44 generator_loss:0.717 discriminator_loss:1.260 accuracy:8.360\n",
            "Epoch:45 generator_loss:0.697 discriminator_loss:1.251 accuracy:8.581\n",
            "Epoch:46 generator_loss:0.735 discriminator_loss:1.231 accuracy:8.558\n",
            "Epoch:47 generator_loss:0.818 discriminator_loss:1.107 accuracy:10.372\n",
            "Epoch:48 generator_loss:0.679 discriminator_loss:1.271 accuracy:7.221\n",
            "Epoch:49 generator_loss:0.715 discriminator_loss:1.264 accuracy:8.907\n",
            "Epoch:50 generator_loss:0.812 discriminator_loss:1.252 accuracy:9.105\n",
            "Epoch:51 generator_loss:0.675 discriminator_loss:1.256 accuracy:8.105\n",
            "Epoch:52 generator_loss:2.713 discriminator_loss:0.483 accuracy:13.535\n",
            "Epoch:53 generator_loss:0.982 discriminator_loss:0.778 accuracy:11.988\n",
            "Epoch:54 generator_loss:0.703 discriminator_loss:1.191 accuracy:8.709\n",
            "Epoch:55 generator_loss:0.881 discriminator_loss:1.038 accuracy:12.244\n",
            "Epoch:56 generator_loss:0.923 discriminator_loss:1.113 accuracy:11.105\n",
            "Epoch:57 generator_loss:0.985 discriminator_loss:0.990 accuracy:12.058\n",
            "Epoch:58 generator_loss:2.845 discriminator_loss:0.178 accuracy:13.965\n",
            "Epoch:59 generator_loss:3.760 discriminator_loss:-0.270 accuracy:15.023\n",
            "Epoch:60 generator_loss:2.411 discriminator_loss:-0.491 accuracy:14.512\n",
            "Epoch:61 generator_loss:1.473 discriminator_loss:0.100 accuracy:12.733\n",
            "Epoch:62 generator_loss:1.506 discriminator_loss:0.859 accuracy:13.012\n",
            "Epoch:63 generator_loss:2.645 discriminator_loss:0.044 accuracy:14.430\n",
            "Epoch:64 generator_loss:1.483 discriminator_loss:0.600 accuracy:12.453\n",
            "Epoch:65 generator_loss:2.453 discriminator_loss:0.118 accuracy:13.302\n",
            "Epoch:66 generator_loss:2.909 discriminator_loss:-4.659 accuracy:14.756\n",
            "Epoch:67 generator_loss:4.899 discriminator_loss:-6.792 accuracy:15.628\n",
            "Epoch:68 generator_loss:6.626 discriminator_loss:-7.162 accuracy:15.756\n",
            "Epoch:69 generator_loss:9.269 discriminator_loss:-7.056 accuracy:15.895\n",
            "Epoch:70 generator_loss:5.740 discriminator_loss:-7.806 accuracy:16.000\n",
            "Epoch:71 generator_loss:7.134 discriminator_loss:-7.737 accuracy:16.000\n",
            "Epoch:72 generator_loss:6.899 discriminator_loss:-7.712 accuracy:16.000\n",
            "Epoch:73 generator_loss:7.456 discriminator_loss:-7.575 accuracy:16.000\n",
            "Epoch:74 generator_loss:8.367 discriminator_loss:-7.707 accuracy:16.000\n",
            "Epoch:75 generator_loss:7.430 discriminator_loss:-7.878 accuracy:16.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-0389bbb56f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-6a3ba1970c30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(trainset_loader, net_g, net_d, optimizer_g, optimizer_d, N_epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimzer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{} generator_loss:{:.3f} discriminator_loss:{:.3f} accuracy:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-c065bb36ce10>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainset_loader, net_g, net_d, optimizer_g, optimizer_d, freeze_d)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_sequences_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fea\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mg_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# print(\"d_fea\",g_fea)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0md_logit_fake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bdf7c5b07597>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, states)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mhD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0msos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mout_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}